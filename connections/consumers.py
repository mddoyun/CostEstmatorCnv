# connections/consumers.py
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.db.models import F
# ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] Count ÏûÑÌè¨Ìä∏ ‚ñº‚ñº‚ñº
from django.db.models import Count
# ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤
# ‚ñº‚ñº‚ñº [ÏàòÏ†ï] AIModel, SplitElement, CostItem ÏûÑÌè¨Ìä∏ Ï∂îÍ∞Ä ‚ñº‚ñº‚ñº
from .models import Project, RawElement, QuantityClassificationTag, QuantityMember, AIModel, SplitElement, CostItem
# ‚ñ≤‚ñ≤‚ñ≤ [ÏàòÏ†ï] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤
import asyncio
# --- Îç∞Ïù¥ÌÑ∞ ÏßÅÎ†¨Ìôî Ìó¨Ìçº Ìï®ÏàòÎì§ ---
def serialize_tags(tags):
    # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ ÏßÅÎ†¨Ìôî ÌôïÏù∏
    # print(f"[DEBUG][serialize_tags] Serializing {len(tags)} tags.") # ÎÑàÎ¨¥ ÎπàÎ≤àÌï† Ïàò ÏûàÏñ¥ Ï£ºÏÑù Ï≤òÎ¶¨
    return [{'id': str(tag.id), 'name': tag.name} for tag in tags]

@database_sync_to_async
def get_total_element_count(project_id):
    # ÎîîÎ≤ÑÍπÖ: Ï¥ù Í∞ùÏ≤¥ Ïàò Ï°∞Ìöå ÏãúÏûë
    print(f"[DEBUG][DB Async][get_total_element_count] Querying total elements for project: {project_id}")
    try:
        count = RawElement.objects.filter(project_id=project_id).count()
        # ÎîîÎ≤ÑÍπÖ: Ï°∞Ìöå Í≤∞Í≥º
        print(f"[DEBUG][DB Async][get_total_element_count] Found {count} elements.")
        return count
    except Project.DoesNotExist:
        # ÎîîÎ≤ÑÍπÖ: ÌîÑÎ°úÏ†ùÌä∏ ÏóÜÏùå
        print(f"[ERROR][DB Async][get_total_element_count] Project {project_id} does not exist.")
        return 0
    except Exception as e:
        # ÎîîÎ≤ÑÍπÖ: Í∏∞ÌÉÄ Ïò§Î•ò
        print(f"[ERROR][DB Async][get_total_element_count] Exception: {e}")
        return 0

@database_sync_to_async
def get_serialized_element_chunk(project_id, offset, limit):
    # ÎîîÎ≤ÑÍπÖ: Ï≤≠ÌÅ¨ Ï°∞Ìöå ÏãúÏûë
    # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Querying chunk for project {project_id}, offset={offset}, limit={limit}") # ÎÑàÎ¨¥ ÎπàÎ≤àÌïòÏó¨ Ï£ºÏÑù Ï≤òÎ¶¨
    try:
        element_chunk_values = list(
            RawElement.objects.filter(project_id=project_id)
            .order_by('id')
            .values('id', 'project_id', 'element_unique_id', 'geometry_volume', 'updated_at', 'raw_data')[offset:offset + limit]
        )
        if not element_chunk_values:
             # ÎîîÎ≤ÑÍπÖ: Îπà Ï≤≠ÌÅ¨
             # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Empty chunk returned.") # ÎÑàÎ¨¥ ÎπàÎ≤àÌïòÏó¨ Ï£ºÏÑù Ï≤òÎ¶¨
             return []
        element_ids_in_chunk = [el['id'] for el in element_chunk_values]
        # ElementClassificationAssignment Î™®Îç∏ import
        from connections.models import ElementClassificationAssignment

        # ÌÉúÍ∑∏ Ìï†Îãπ Ï†ïÎ≥¥ Ï°∞Ìöå (assignment_type Ìè¨Ìï®)
        tags_qs = (
            ElementClassificationAssignment.objects
            .filter(raw_element_id__in=element_ids_in_chunk)
            .select_related('classification_tag')
            .values('raw_element_id', 'classification_tag__name', 'assignment_type')
        )
        tags_by_element_id = {}
        tag_details_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['raw_element_id']
            tag_name = tag_data['classification_tag__name']
            assignment_type = tag_data['assignment_type']

            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
                tag_details_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_name)
            tag_details_by_element_id[el_id].append({
                'name': tag_name,
                'assignment_type': assignment_type
            })

        for element_data in element_chunk_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['classification_tags_details'] = tag_details_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            # Convert Decimal to float for JSON serialization
            if element_data.get('geometry_volume') is not None:
                element_data['geometry_volume'] = float(element_data['geometry_volume'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ÎîîÎ≤ÑÍπÖ: Ï≤≠ÌÅ¨ ÏßÅÎ†¨Ìôî ÏôÑÎ£å
        # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Serialized {len(element_chunk_values)} elements in chunk.") # ÎÑàÎ¨¥ ÎπàÎ≤àÌïòÏó¨ Ï£ºÏÑù Ï≤òÎ¶¨
        return element_chunk_values
    except Exception as e:
        # ÎîîÎ≤ÑÍπÖ: Ïò§Î•ò Î∞úÏÉù
        print(f"[ERROR][DB Async][get_serialized_element_chunk] Exception: {e}")
        return []

@database_sync_to_async
def serialize_specific_elements(element_ids):
    # ÎîîÎ≤ÑÍπÖ: ÌäπÏ†ï Í∞ùÏ≤¥ ÏßÅÎ†¨Ìôî ÏãúÏûë
    print(f"[DEBUG][DB Async][serialize_specific_elements] Serializing {len(element_ids)} specific elements.")
    try:
        elements_values = list(
            RawElement.objects.filter(id__in=element_ids)
            .values('id', 'project_id', 'element_unique_id', 'updated_at', 'raw_data')
        )
        if not elements_values:
            # ÎîîÎ≤ÑÍπÖ: ÎåÄÏÉÅ Í∞ùÏ≤¥ ÏóÜÏùå
             print(f"[DEBUG][DB Async][serialize_specific_elements] No elements found for the given IDs.")
             return []
        # ElementClassificationAssignment Î™®Îç∏ import
        from connections.models import ElementClassificationAssignment

        # ÌÉúÍ∑∏ Ìï†Îãπ Ï†ïÎ≥¥ Ï°∞Ìöå (assignment_type Ìè¨Ìï®)
        tags_qs = (
            ElementClassificationAssignment.objects
            .filter(raw_element_id__in=element_ids)
            .select_related('classification_tag')
            .values('raw_element_id', 'classification_tag__name', 'assignment_type')
        )
        tags_by_element_id = {}
        tag_details_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['raw_element_id']
            tag_name = tag_data['classification_tag__name']
            assignment_type = tag_data['assignment_type']

            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
                tag_details_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_name)
            tag_details_by_element_id[el_id].append({
                'name': tag_name,
                'assignment_type': assignment_type
            })

        for element_data in elements_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['classification_tags_details'] = tag_details_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ÎîîÎ≤ÑÍπÖ: ÏßÅÎ†¨Ìôî ÏôÑÎ£å
        print(f"[DEBUG][DB Async][serialize_specific_elements] Successfully serialized {len(elements_values)} elements.")
        return elements_values
    except Exception as e:
        # ÎîîÎ≤ÑÍπÖ: Ïò§Î•ò Î∞úÏÉù
        print(f"[ERROR][DB Async][serialize_specific_elements] Exception: {e}")
        return []

@database_sync_to_async
def get_split_elements_for_project(project_id):
    """
    ÌîÑÎ°úÏ†ùÌä∏Ïùò Î™®Îì† ÌôúÏÑ± Î∂ÑÌï† Í∞ùÏ≤¥Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§.

    Returns:
        tuple: (split_elements_list, raw_element_ids_with_splits_set)
        - split_elements_list: Î∂ÑÌï† Í∞ùÏ≤¥ Î™©Î°ù (ÏßÅÎ†¨ÌôîÎê®)
        - raw_element_ids_with_splits_set: Î∂ÑÌï†Ïù¥ ÏûàÎäî RawElement ID Î™©Î°ù (set)
    """
    print(f"[DEBUG][DB Async][get_split_elements_for_project] Querying split elements for project: {project_id}")

    try:
        # ÌôúÏÑ± Î∂ÑÌï† Í∞ùÏ≤¥ Ï°∞Ìöå
        split_elements = SplitElement.objects.filter(
            project_id=project_id,
            is_active=True
        ).select_related('raw_element').values(
            'id',
            'raw_element_id',
            'parent_split_id',
            'original_geometry_volume',
            'geometry_volume',
            'volume_ratio',
            'split_method',
            'split_axis',
            'split_position',
            'split_part_type',
            'geometry_data',
            'sketch_data',
            'metadata',
            'created_at',
            'updated_at'
        )

        split_elements_list = list(split_elements)

        # Î∂ÑÌï†Ïù¥ ÏûàÎäî RawElement IDÎì§ÏùÑ ÏàòÏßë
        raw_element_ids_with_splits = set()

        # ÏßÅÎ†¨Ìôî Î∞è RawElement ID ÏàòÏßë
        for split_data in split_elements_list:
            # UUIDÎ•º Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò
            split_data['id'] = str(split_data['id'])
            split_data['raw_element_id'] = str(split_data['raw_element_id'])

            # Î∂ÑÌï†Ïù¥ ÏûàÎäî RawElement ID Ï∂îÍ∞Ä
            raw_element_ids_with_splits.add(split_data['raw_element_id'])

            if split_data.get('parent_split_id'):
                split_data['parent_split_id'] = str(split_data['parent_split_id'])

            # DecimalÏùÑ floatÎ°ú Î≥ÄÌôò
            if split_data.get('original_geometry_volume') is not None:
                split_data['original_geometry_volume'] = float(split_data['original_geometry_volume'])
            if split_data.get('geometry_volume') is not None:
                split_data['geometry_volume'] = float(split_data['geometry_volume'])
            if split_data.get('volume_ratio') is not None:
                split_data['volume_ratio'] = float(split_data['volume_ratio'])
            if split_data.get('split_position') is not None:
                split_data['split_position'] = float(split_data['split_position'])

            # DatetimeÏùÑ ISO ÌòïÏãù Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò
            split_data['created_at'] = split_data['created_at'].isoformat()
            split_data['updated_at'] = split_data['updated_at'].isoformat()

        print(f"[DEBUG][DB Async][get_split_elements_for_project] Found {len(split_elements_list)} active split elements")
        print(f"[DEBUG][DB Async][get_split_elements_for_project] {len(raw_element_ids_with_splits)} RawElements have splits")

        return split_elements_list, raw_element_ids_with_splits

    except Exception as e:
        print(f"[ERROR][DB Async][get_split_elements_for_project] Exception: {e}")
        import traceback
        traceback.print_exc()
        return [], set()

class RevitConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.all_incoming_uids = set()
        self.project_id_for_fetch = None
        path = self.scope['path']
        if 'revit-connector' in path:
            self.group_name = 'revit_broadcast_group'
            print(f"‚úÖ [{self.__class__.__name__}] Revit ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.group_name}' Í∑∏Î£πÏóê Ï∞∏Ïó¨Ìï©ÎãàÎã§.") # ÎîîÎ≤ÑÍπÖ Ï∂îÍ∞Ä
        elif 'blender-connector' in path:
            self.group_name = 'blender_broadcast_group'
            print(f"‚úÖ [{self.__class__.__name__}] Blender ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.group_name}' Í∑∏Î£πÏóê Ï∞∏Ïó¨Ìï©ÎãàÎã§.") # ÎîîÎ≤ÑÍπÖ Ï∂îÍ∞Ä
        else:
            self.group_name = None
            print(f"‚ö†Ô∏è [{self.__class__.__name__}] Ïïå Ïàò ÏóÜÎäî Í≤ΩÎ°úÎ°ú ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ïó∞Í≤∞ ÏãúÎèÑ: {path}") # ÎîîÎ≤ÑÍπÖ Ï∂îÍ∞Ä

        if self.group_name:
            # print(f"‚úÖ [{self.__class__.__name__}] ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.group_name}' Í∑∏Î£πÏóê Ï∞∏Ïó¨Ìï©ÎãàÎã§.") # ÏúÑÏóêÏÑú Ïù¥ÎØ∏ Ï∂úÎ†•
            await self.channel_layer.group_add(self.group_name, self.channel_name)
        await self.accept()

    async def disconnect(self, close_code):
        if hasattr(self, 'group_name') and self.group_name:
            print(f"‚ùå [{self.__class__.__name__}] ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.group_name}' Í∑∏Î£πÏóêÏÑú ÎÇòÍ∞ëÎãàÎã§ (Code: {close_code}).") # ÎîîÎ≤ÑÍπÖ Ï∂îÍ∞Ä
            await self.channel_layer.group_discard(self.group_name, self.channel_name)

    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"\n‚úâÔ∏è  [{self.__class__.__name__}] ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î°úÎ∂ÄÌÑ∞ Î©îÏãúÏßÄ ÏàòÏã†: type='{msg_type}'") # Í∏∞Ï°¥ print Ïú†ÏßÄ

        if msg_type == 'revit_selection_response':
            # ÎîîÎ≤ÑÍπÖ: ÏÑ†ÌÉù ÏùëÎãµ Ï†ÑÎã¨
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÏàòÏã†Ìïú ÏÑ†ÌÉù Ï†ïÎ≥¥({len(payload)}Í∞ú ID)Î•º ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°ú Ï†ÑÎã¨Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {'type': 'broadcast_selection', 'unique_ids': payload}
            )
        elif msg_type == 'fetch_progress_start':
            print("[DEBUG] 'fetch_progress_start' ÏàòÏã†. ÎèôÍ∏∞Ìôî ÏÑ∏ÏÖòÏùÑ ÏãúÏûëÌï©ÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            self.all_incoming_uids.clear()

            # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] payloadÏóêÏÑú project_idÎ•º Í∞ÄÏ†∏Ïò§Îäî ÎåÄÏã†, Ïù¥ÎØ∏ Ï†ÄÏû•Îêú Í∞íÏùÑ ÌôïÏù∏Ìï©ÎãàÎã§. ‚ñº‚ñº‚ñº
            print(f"  - ÌòÑÏû¨ ÏÑ∏ÏÖòÏùò ÌîÑÎ°úÏ†ùÌä∏ ID: {self.project_id_for_fetch}") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            if not self.project_id_for_fetch:
                print("[CRITICAL ERROR] 'fetch_progress_start' ÏãúÏ†êÏóê ÌîÑÎ°úÏ†ùÌä∏ IDÍ∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§! ÎèôÍ∏∞ÌôîÍ∞Ä Ïã§Ìå®Ìï† Ïàò ÏûàÏäµÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            # ‚ñ≤‚ñ≤‚ñ≤ [ÏàòÏ†ï] Ïó¨Í∏∞ÍπåÏßÄ ÏûÖÎãàÎã§. ‚ñ≤‚ñ≤‚ñ≤

            print(f"  - Ï†ÑÏ≤¥ Í∞ùÏ≤¥ Ïàò: {payload.get('total_elements')}") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            # ÎîîÎ≤ÑÍπÖ: ÏßÑÌñâ ÏãúÏûë Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ ÏãúÏûë Ï†ïÎ≥¥Î•º ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°ú Ï†ÑÎã¨Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        elif msg_type == 'fetch_progress_update':
            print(f"[DEBUG] 'fetch_progress_update' ÏàòÏã†. Ï≤òÎ¶¨Îêú Í∞ùÏ≤¥: {payload.get('processed_count')}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] payloadÏùò project_id ÎåÄÏã† selfÏóê Ï†ÄÏû•Îêú project_idÎ•º ÏÇ¨Ïö©Ìï©ÎãàÎã§. ‚ñº‚ñº‚ñº
            project_id = self.project_id_for_fetch
            # ‚ñ≤‚ñ≤‚ñ≤ [ÏàòÏ†ï] Ïó¨Í∏∞ÍπåÏßÄ ÏûÖÎãàÎã§. ‚ñ≤‚ñ≤‚ñ≤

            elements_data = [json.loads(s) for s in payload.get('elements', [])]

            chunk_uids = {item['UniqueId'] for item in elements_data if item and 'UniqueId' in item}
            self.all_incoming_uids.update(chunk_uids)
            print(f"  - Ïù¥Î≤à Ï≤≠ÌÅ¨Ïùò UniqueId {len(chunk_uids)}Í∞ú Ï∂îÍ∞Ä. ÌòÑÏû¨ÍπåÏßÄ Ï¥ù {len(self.all_incoming_uids)}Í∞ú ÏàòÏã†.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # ÎîîÎ≤ÑÍπÖ: ÏßÑÌñâ ÏóÖÎç∞Ïù¥Ìä∏ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Îç∞Ïù¥ÌÑ∞ ÏßÑÌñâÎ•† ÏóÖÎç∞Ïù¥Ìä∏ Ï†ïÎ≥¥Î•º ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°ú Ï†ÑÎã¨Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
            if project_id and elements_data:
                # ÎîîÎ≤ÑÍπÖ: DB ÎèôÍ∏∞Ìôî ÏãúÏûë
                print(f"  üîÑ [{self.__class__.__name__}] ÏàòÏã†Ìïú {len(elements_data)}Í∞ú Í∞ùÏ≤¥Ïóê ÎåÄÌïú DB ÎèôÍ∏∞ÌôîÎ•º ÏãúÏûëÌï©ÎãàÎã§ (Project: {project_id}).")
                await asyncio.shield(self.sync_chunk_of_elements(project_id, elements_data))

        elif msg_type == 'fetch_progress_complete':
            print("[DEBUG] 'fetch_progress_complete' ÏàòÏã†. ÎèôÍ∏∞ÌôîÎ•º ÎßàÎ¨¥Î¶¨ÌïòÍ≥† ÏÇ≠Ï†ú ÏûëÏóÖÏùÑ ÏãúÏûëÌï©ÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            if self.project_id_for_fetch:
                # ÎîîÎ≤ÑÍπÖ: ÏÇ≠Ï†ú ÏûëÏóÖ ÏãúÏûë
                print(f"  üóëÔ∏è [{self.__class__.__name__}] Ïò§ÎûòÎêú Í∞ùÏ≤¥ ÏÇ≠Ï†ú ÏûëÏóÖÏùÑ ÏãúÏûëÌï©ÎãàÎã§ (Project: {self.project_id_for_fetch}).")
                await cleanup_old_elements(self.project_id_for_fetch, self.all_incoming_uids)
            else:
                print("[WARNING] 'project_id_for_fetch'Í∞Ä ÏÑ§Ï†ïÎêòÏßÄ ÏïäÏïÑ ÏÇ≠Ï†ú ÏûëÏóÖÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # ÎîîÎ≤ÑÍπÖ: ÏôÑÎ£å Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ ÏôÑÎ£å Ï†ïÎ≥¥Î•º ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°ú Ï†ÑÎã¨Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        else:
            print(f"[WARNING] Ï≤òÎ¶¨ÎêòÏßÄ ÏïäÏùÄ Î©îÏãúÏßÄ Ïú†ÌòïÏûÖÎãàÎã§: {msg_type}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

    async def send_command(self, event):
        command_data = event['command_data']

        # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ Î™ÖÎ†πÏùº Í≤ΩÏö∞, project_idÎ•º ÎØ∏Î¶¨ Ï†ÄÏû•Ìï©ÎãàÎã§. ‚ñº‚ñº‚ñº
        if command_data.get('command') == 'fetch_all_elements_chunked':
            project_id = command_data.get('project_id')
            self.project_id_for_fetch = project_id
            print(f"üöÄ [{self.__class__.__name__}] Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ ÏÑ∏ÏÖò ÏãúÏûë. Project ID '{project_id}'Î•º Ï†ÄÏû•Ìï©ÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ
        # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ÏûÖÎãàÎã§. ‚ñ≤‚ñ≤‚ñ≤

        print(f"‚û°Ô∏è  [{self.__class__.__name__}] '{self.group_name}' Í∑∏Î£πÏùò ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î°ú Î™ÖÎ†πÏùÑ Î≥¥ÎÉÖÎãàÎã§: {command_data.get('command')}") # Í∏∞Ï°¥ print Ïú†ÏßÄ
        try: # ÎîîÎ≤ÑÍπÖ: send Ïã§Ìå® Ïãú Î°úÍ∑∏ Ï∂îÍ∞Ä
            await self.send(text_data=json.dumps(command_data))
        except Exception as e:
            print(f"[ERROR][{self.__class__.__name__}] Failed to send command to client: {e}")


    @database_sync_to_async
    def sync_chunk_of_elements(self, project_id, parsed_data):
        print(f"  [DB Sync] Ï≤≠ÌÅ¨ ÎèôÍ∏∞Ìôî ÏãúÏûë: {len(parsed_data)}Í∞ú Í∞ùÏ≤¥") # Í∏∞Ï°¥ print Ïú†ÏßÄ
        try:
            project = Project.objects.get(id=project_id)
            uids_in_chunk = [item['UniqueId'] for item in parsed_data if item and 'UniqueId' in item]
            existing_elements_map = {el.element_unique_id: el for el in project.raw_elements.filter(element_unique_id__in=uids_in_chunk)}
            print(f"    - DBÏóêÏÑú Í∏∞Ï°¥ Í∞ùÏ≤¥ {len(existing_elements_map)}Í∞ú Ï∞æÏùå.") # ÎîîÎ≤ÑÍπÖ Ï∂îÍ∞Ä

            to_update, to_create = [], []
            for item in parsed_data:
                if not item or 'UniqueId' not in item: continue
                uid = item['UniqueId']
                if uid in existing_elements_map:
                    elem = existing_elements_map[uid]
                    # [Í∞úÏÑ†] raw_dataÍ∞Ä Ïã§Ï†úÎ°ú Î≥ÄÍ≤ΩÎêòÏóàÎäîÏßÄ ÌôïÏù∏ ÌõÑ ÏóÖÎç∞Ïù¥Ìä∏ Î™©Î°ùÏóê Ï∂îÍ∞Ä (ÏÑ†ÌÉù ÏÇ¨Ìï≠)
                    if elem.raw_data != item:
                        elem.raw_data = item
                        to_update.append(elem)
                else:
                    to_create.append(RawElement(project=project, element_unique_id=uid, raw_data=item))

            if to_update:
                updated_ids = [el.id for el in to_update] # ÎîîÎ≤ÑÍπÖÏö©
                RawElement.objects.bulk_update(to_update, ['raw_data'])
                print(f"    - {len(to_update)}Í∞ú Í∞ùÏ≤¥ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å. (IDs: {updated_ids[:5]}...)") # Í∏∞Ï°¥ print Ïú†ÏßÄ (ID Ï∂îÍ∞Ä)

                # Geometry volume Í≥ÑÏÇ∞ Î∞è ÏóÖÎç∞Ïù¥Ìä∏
                updated_with_volume = []
                for elem in to_update:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        updated_with_volume.append(elem)
                if updated_with_volume:
                    RawElement.objects.bulk_update(updated_with_volume, ['geometry_volume'])
                    print(f"    - {len(updated_with_volume)}Í∞ú Í∞ùÏ≤¥Ïùò Geometry volume Í≥ÑÏÇ∞ ÏôÑÎ£å.")

            if to_create:
                created_objs = RawElement.objects.bulk_create(to_create, ignore_conflicts=True)
                print(f"    - {len(created_objs)}Í∞ú Í∞ùÏ≤¥ ÏÉàÎ°ú ÏÉùÏÑ± ÏôÑÎ£å.") # Í∏∞Ï°¥ print Ïú†ÏßÄ (Ïã§Ï†ú ÏÉùÏÑ±Îêú Ïàò ÏÇ¨Ïö©)

                # Geometry volume Í≥ÑÏÇ∞ Î∞è ÏóÖÎç∞Ïù¥Ìä∏
                created_with_volume = []
                for elem in created_objs:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        created_with_volume.append(elem)
                if created_with_volume:
                    RawElement.objects.bulk_update(created_with_volume, ['geometry_volume'])
                    print(f"    - {len(created_with_volume)}Í∞ú Í∞ùÏ≤¥Ïùò Geometry volume Í≥ÑÏÇ∞ ÏôÑÎ£å.")

        except Exception as e:
            print(f"[ERROR] sync_chunk_of_elements DB ÏûëÏóÖ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

@database_sync_to_async
def cleanup_old_elements(project_id, incoming_uids):
    print(f"  [DB Cleanup] ÏÇ≠Ï†ú ÏûëÏóÖ ÏãúÏûë (Project ID: {project_id})") # Í∏∞Ï°¥ print Ïú†ÏßÄ
    try:
        project = Project.objects.get(id=project_id)

        # [Í∞úÏÑ†] QuerySet ÏÇ¨Ïö© ÏµúÏ†ÅÌôî (values_list ÎåÄÏã† set ÏßÅÏ†ë ÏÇ¨Ïö©)
        db_uids = set(project.raw_elements.values_list('element_unique_id', flat=True))
        print(f"    - ÌòÑÏû¨ DBÏóê Ï°¥Ïû¨ÌïòÎäî UniqueId Ïàò: {len(db_uids)}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

        incoming_uids_set = set(incoming_uids)
        print(f"    - Ïù¥Î≤à ÎèôÍ∏∞ÌôîÏóêÏÑú Î∞õÏùÄ UniqueId Ïàò: {len(incoming_uids_set)}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

        to_delete_uids = db_uids - incoming_uids_set
        print(f"    - ÏÇ≠Ï†ú ÎåÄÏÉÅ UniqueId Ïàò: {len(to_delete_uids)}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

        if to_delete_uids:
            print(f"    - ÏÇ≠Ï†ú ÎåÄÏÉÅ ID (ÏµúÎåÄ 10Í∞ú ÌëúÏãú): {list(to_delete_uids)[:10]}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] RawElementÎ•º ÏÇ≠Ï†úÌïòÍ∏∞ Ï†ÑÏóê, Ïó∞Í¥ÄÎêú Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏ Î∞è Ï†ïÎ¶¨ ‚ñº‚ñº‚ñº

            # 1. Ïó∞Í¥ÄÎêú SplitElement ÌôïÏù∏ (CASCADEÎ°ú ÏûêÎèô ÏÇ≠Ï†úÎê®)
            split_elements_count = SplitElement.objects.filter(
                project=project,
                raw_element__element_unique_id__in=to_delete_uids
            ).count()
            print(f"    - [SplitElement Cleanup] {split_elements_count}Í∞úÏùò Î∂ÑÌï† Í∞ùÏ≤¥Í∞Ä CASCADEÎ°ú ÏûêÎèô ÏÇ≠Ï†úÎê† ÏòàÏ†ïÏûÖÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # 2. Ïó∞Í¥ÄÎêú QuantityMember ÌôïÏù∏ Î∞è ÏÇ≠Ï†ú (SET_NULLÏù¥ÎØÄÎ°ú Î™ÖÏãúÏ†Å ÏÇ≠Ï†ú)
            print(f"    - [QuantityMember Cleanup] ÏÇ≠Ï†úÎê† RawElementÏôÄ Ïó∞Í¥ÄÎêú ÏàòÎüâÏÇ∞Ï∂úÎ∂ÄÏû¨Î•º Î®ºÏ†Ä ÏÇ≠Ï†úÌï©ÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

            # raw_element ÌïÑÎìúÍ∞Ä nullÏù¥ ÏïÑÎãå(Ï¶â, BIM Í∞ùÏ≤¥ÏôÄ Ïó∞Í≥ÑÎêú) ÏàòÎüâÏÇ∞Ï∂úÎ∂ÄÏû¨ Ï§ëÏóêÏÑú
            # ÏÇ≠Ï†úÎê† RawElementÏùò unique_idÎ•º Í∞ÄÏßÑ Î∂ÄÏû¨Îì§ÏùÑ Ï∞æÏïÑ ÏÇ≠Ï†úÌï©ÎãàÎã§.
            deletable_members = QuantityMember.objects.filter(
                project=project,
                raw_element__element_unique_id__in=to_delete_uids
            )

            member_deleted_count, deleted_details = deletable_members.delete() # ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Î∞õÏùÑ Ïàò ÏûàÏùå
            print(f"    - [QuantityMember Cleanup] {member_deleted_count}Í∞úÏùò Ïó∞Í¥ÄÎêú ÏàòÎüâÏÇ∞Ï∂úÎ∂ÄÏû¨Î•º ÏÇ≠Ï†úÌñàÏäµÎãàÎã§. Details: {deleted_details}") # Í∏∞Ï°¥ print Ïú†ÏßÄ (ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Ï∂îÍ∞Ä)
            # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ÏûÖÎãàÎã§. ‚ñ≤‚ñ≤‚ñ≤

            deleted_count, deleted_raw_details = project.raw_elements.filter(element_unique_id__in=to_delete_uids).delete()
            print(f"    - DBÏóêÏÑú {deleted_count}Í∞úÏùò Ïò§ÎûòÎêú RawElement Í∞ùÏ≤¥Î•º ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÇ≠Ï†úÌñàÏäµÎãàÎã§. Details: {deleted_raw_details}") # Í∏∞Ï°¥ print Ïú†ÏßÄ (ÏÉÅÏÑ∏ Ï†ïÎ≥¥ Ï∂îÍ∞Ä)
            print(f"    - ‚úÖ CASCADE Ìö®Í≥ºÎ°ú Ïù∏Ìï¥ Í¥ÄÎ†®Îêú SplitElement, QuantityMember(Î∂ÑÌï†), CostItem(Î∂ÑÌï†)ÎèÑ Ìï®Íªò ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.")
        else:
            print("    - ÏÇ≠Ï†úÌï† Í∞ùÏ≤¥Í∞Ä ÏóÜÏäµÎãàÎã§. Î™®Îì† Îç∞Ïù¥ÌÑ∞Í∞Ä ÏµúÏã† ÏÉÅÌÉúÏûÖÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

    except Exception as e:
        print(f"[ERROR] cleanup_old_elements DB ÏûëÏóÖ Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}") # Í∏∞Ï°¥ print Ïú†ÏßÄ

class FrontendConsumer(AsyncWebsocketConsumer):
    frontend_group_name = 'frontend_group'
    async def connect(self):
        # ÎîîÎ≤ÑÍπÖ: ÌîÑÎ°†Ìä∏ÏóîÎìú Ïó∞Í≤∞
        print(f"‚úÖ [{self.__class__.__name__}] Ïõπ Î∏åÎùºÏö∞Ï†Ä ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.frontend_group_name}' Í∑∏Î£πÏóê Ï∞∏Ïó¨Ìï©ÎãàÎã§.")
        await self.channel_layer.group_add(self.frontend_group_name, self.channel_name); await self.accept()
    async def disconnect(self, close_code):
        # ÎîîÎ≤ÑÍπÖ: ÌîÑÎ°†Ìä∏ÏóîÎìú Ïó∞Í≤∞ Ìï¥Ï†ú
        print(f"‚ùå [{self.__class__.__name__}] Ïõπ Î∏åÎùºÏö∞Ï†Ä ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Í∞Ä '{self.frontend_group_name}' Í∑∏Î£πÏóêÏÑú ÎÇòÍ∞ëÎãàÎã§ (Code: {close_code}).")
        await self.channel_layer.group_discard(self.frontend_group_name, self.channel_name)


    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"‚úâÔ∏è [{self.__class__.__name__}] Ïõπ Î∏åÎùºÏö∞Ï†ÄÎ°úÎ∂ÄÌÑ∞ Î©îÏãúÏßÄ ÏàòÏã†: type='{msg_type}'") # Í∏∞Ï°¥ print Ïú†ÏßÄ

        if msg_type == 'command_to_client':
            target_group = payload.pop('target_group', 'revit_broadcast_group')
            print(f"   ‚û°Ô∏è  '{target_group}' Í∑∏Î£πÏúºÎ°ú Î™ÖÎ†πÏùÑ Ï†ÑÎã¨Ìï©ÎãàÎã§: {payload}") # Í∏∞Ï°¥ print Ïú†ÏßÄ
            await self.channel_layer.group_send(target_group, {'type': 'send.command', 'command_data': payload})

        # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] get_all_elements Î©îÏãúÏßÄ Ï≤òÎ¶¨ Î∂ÄÎ∂ÑÏóê printÎ¨∏ Ï∂îÍ∞Ä ‚ñº‚ñº‚ñº
        elif msg_type == 'get_all_elements':
            project_id = payload.get('project_id')
            if project_id:
                print(f"\n[DEBUG] ÌîÑÎ°†Ìä∏ÏóîÎìúÎ°úÎ∂ÄÌÑ∞ '{project_id}' ÌîÑÎ°úÏ†ùÌä∏Ïùò Î™®Îì† Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏöîÏ≤≠ÏùÑ Î∞õÏïòÏäµÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ
                total_elements = await get_total_element_count(project_id)
                print(f"[DEBUG] Ï¥ù {total_elements}Í∞úÏùò Í∞ùÏ≤¥Î•º Ï†ÑÏÜ° ÏãúÏûëÌï©ÎãàÎã§.") # Í∏∞Ï°¥ print Ïú†ÏßÄ

                # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] Î∂ÑÌï† Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå ‚ñº‚ñº‚ñº
                split_elements, raw_element_ids_with_splits = await get_split_elements_for_project(project_id)
                print(f"[DEBUG] {len(split_elements)}Í∞úÏùò ÌôúÏÑ± Î∂ÑÌï† Í∞ùÏ≤¥Î•º Ï∞æÏïòÏäµÎãàÎã§.")
                print(f"[DEBUG] {len(raw_element_ids_with_splits)}Í∞úÏùò BIM ÏõêÎ≥∏ Í∞ùÏ≤¥Í∞Ä Î∂ÑÌï†ÎêòÏóàÏäµÎãàÎã§.")
                # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

                await self.send(text_data=json.dumps({
                    'type': 'revit_data_start',
                    'payload': {
                        'total': total_elements,
                        'split_elements': split_elements,  # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] Î∂ÑÌï† Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞ Ï†ÑÏÜ° ‚ñº‚ñº‚ñº
                        'raw_element_ids_with_splits': list(raw_element_ids_with_splits)  # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] Î∂ÑÌï†Îêú BIM ÏõêÎ≥∏ ID Î™©Î°ù ‚ñº‚ñº‚ñº
                    }
                }))

                CHUNK_SIZE = 1000 # ÏÑ±Îä• ÌÖåÏä§Ìä∏ ÌõÑ Ï°∞Ï†à Í∞ÄÎä•
                sent_count = 0
                for offset in range(0, total_elements, CHUNK_SIZE):
                    chunk = await get_serialized_element_chunk(project_id, offset, CHUNK_SIZE)
                    if chunk:
                        await self.send(text_data=json.dumps({'type': 'revit_data_chunk', 'payload': chunk}))
                        sent_count += len(chunk)
                        # ÎîîÎ≤ÑÍπÖ: Ï≤≠ÌÅ¨ Ï†ÑÏÜ° Î°úÍ∑∏ (ÎÑàÎ¨¥ ÎπàÎ≤àÌï† Ïàò ÏûàÏúºÎØÄÎ°ú Ï£ºÏÑù Ï≤òÎ¶¨ ÎòêÎäî Ï°∞Í±¥Î∂Ä Ï∂úÎ†• Í≥†Î†§)
                        # print(f"    [WebSocket Send] Sent chunk: {offset+1}-{sent_count}/{total_elements}")
                    await asyncio.sleep(0.01) # Î∂ÄÌïò Î∂ÑÏÇ∞ÏùÑ ÏúÑÌïú ÏïΩÍ∞ÑÏùò ÏßÄÏó∞

                print(f"[DEBUG] {sent_count}Í∞ú Í∞ùÏ≤¥ Ï†ÑÏÜ°ÏùÑ ÏôÑÎ£åÌñàÏäµÎãàÎã§ (Ï¥ù {total_elements}Í∞ú ÎåÄÏÉÅ).") # Í∏∞Ï°¥ print Ïú†ÏßÄ (Ïã§Ï†ú Ï†ÑÏÜ°Îêú Ïàò Ìè¨Ìï®)
                await self.send(text_data=json.dumps({'type': 'revit_data_complete'}))
        # ‚ñ≤‚ñ≤‚ñ≤ [ÏàòÏ†ï] Ïó¨Í∏∞ÍπåÏßÄ ÏûÖÎãàÎã§. ‚ñ≤‚ñ≤‚ñ≤

        elif msg_type == 'get_tags':
            project_id = payload.get('project_id')
            if project_id:
                # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ ÏöîÏ≤≠
                print(f"[DEBUG] '{project_id}' ÌîÑÎ°úÏ†ùÌä∏Ïùò ÌÉúÍ∑∏ Î™©Î°ù ÏöîÏ≤≠ ÏàòÏã†.")
                tags = await self.db_get_tags(project_id)
                await self.send_tags_update(tags)
        
        elif msg_type in ['create_tag', 'update_tag']:
            project_id = payload.get('project_id')
            if not project_id: return
            if msg_type == 'create_tag':
                # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ ÏÉùÏÑ± ÏöîÏ≤≠
                print(f"[DEBUG] ÌÉúÍ∑∏ ÏÉùÏÑ± ÏöîÏ≤≠: name='{payload.get('name')}'")
                await self.db_create_tag(project_id, payload.get('name'))
            elif msg_type == 'update_tag':
                # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ ÏàòÏ†ï ÏöîÏ≤≠
                print(f"[DEBUG] ÌÉúÍ∑∏ ÏàòÏ†ï ÏöîÏ≤≠: id='{payload.get('tag_id')}', new_name='{payload.get('new_name')}'")
                await self.db_update_tag(payload.get('tag_id'), payload.get('new_name'))

            # ÏÉùÏÑ± ÎòêÎäî ÏàòÏ†ï ÌõÑÏóêÎäî ÌÉúÍ∑∏ Î™©Î°ùÎßå ÏóÖÎç∞Ïù¥Ìä∏ÌïòÏó¨ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.
            tags = await self.db_get_tags(project_id)
            # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ Î™©Î°ù Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÉúÍ∑∏ Î™©Î°ùÏùÑ Î™®Îì† ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î°ú Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

        elif msg_type == 'delete_tag':
            project_id = payload.get('project_id')
            tag_id = payload.get('tag_id')
            if not all([project_id, tag_id]): return
            # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ ÏÇ≠Ï†ú ÏöîÏ≤≠
            print(f"[DEBUG] ÌÉúÍ∑∏ ÏÇ≠Ï†ú ÏöîÏ≤≠: id='{tag_id}'")

            # 1. ÌÉúÍ∑∏Î•º ÏÇ≠Ï†úÌïòÍ≥†, ÏòÅÌñ•ÏùÑ Î∞õÏïòÎçò elementÎì§Ïùò ID Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.
            affected_ids = await self.db_delete_tag(tag_id)
            # ÎîîÎ≤ÑÍπÖ: ÏÇ≠Ï†ú Í≤∞Í≥º Î∞è ÏòÅÌñ• Î∞õÏùÄ Í∞ùÏ≤¥ ID
            print(f"  - ÌÉúÍ∑∏ ÏÇ≠Ï†ú ÏôÑÎ£å. ÏòÅÌñ• Î∞õÏùÄ Í∞ùÏ≤¥ Ïàò: {len(affected_ids)}")

            # 2. Î≥ÄÍ≤ΩÎêú Ï†ÑÏ≤¥ ÌÉúÍ∑∏ Î™©Î°ùÏùÑ Î™®Îì† ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Ïóê Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.
            tags = await self.db_get_tags(project_id)
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÏóÖÎç∞Ïù¥Ìä∏Îêú ÌÉúÍ∑∏ Î™©Î°ùÏùÑ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

            # 3. ÎßåÏïΩ ÏòÅÌñ•ÏùÑ Î∞õÏùÄ elementÍ∞Ä ÏûàÏóàÎã§Î©¥, Ìï¥Îãπ elementÎì§Ïùò ÏµúÏã† Ï†ïÎ≥¥Î•º Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.
            if affected_ids:
                elements = await serialize_specific_elements(affected_ids)
                print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÏòÅÌñ• Î∞õÏùÄ {len(elements)}Í∞ú Í∞ùÏ≤¥Ïùò ÏóÖÎç∞Ïù¥Ìä∏ Ï†ïÎ≥¥Î•º Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.")
                await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        elif msg_type in ['assign_tags', 'clear_tags']:
            element_ids = payload.get('element_ids')
            if msg_type == 'assign_tags':
                # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ Ìï†Îãπ ÏöîÏ≤≠
                print(f"[DEBUG] ÌÉúÍ∑∏ Ìï†Îãπ ÏöîÏ≤≠: tag_id='{payload.get('tag_id')}', elements={len(element_ids)}Í∞ú")
                await self.db_assign_tags(payload.get('tag_id'), element_ids)
            elif msg_type == 'clear_tags':
                # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ Ï†úÍ±∞ ÏöîÏ≤≠
                print(f"[DEBUG] ÌÉúÍ∑∏ Ï†úÍ±∞ ÏöîÏ≤≠: elements={len(element_ids)}Í∞ú")
                await self.db_clear_tags(element_ids)
            elements = await serialize_specific_elements(element_ids)
            # ÎîîÎ≤ÑÍπÖ: Í∞ùÏ≤¥ ÏóÖÎç∞Ïù¥Ìä∏ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
            print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÏóÖÎç∞Ïù¥Ìä∏Îêú {len(elements)}Í∞ú Í∞ùÏ≤¥ Ï†ïÎ≥¥Î•º Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏Ìï©ÎãàÎã§.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] AI ÌïôÏäµ ÏÉÅÌÉú Ìè¥ÎßÅ ÏöîÏ≤≠ Ï≤òÎ¶¨ ‚ñº‚ñº‚ñº
        elif msg_type == 'get_training_status':
             task_id = payload.get('task_id')
             if task_id and task_id in training_progress:
                 print(f"[DEBUG] AI ÌïôÏäµ ÏÉÅÌÉú ÏöîÏ≤≠ ÏàòÏã† (Task ID: {task_id}). ÌòÑÏû¨ ÏÉÅÌÉú Ï†ÑÏÜ°.")
                 await self.send(text_data=json.dumps({
                     'type': 'training_progress_update',
                     'project_id': payload.get('project_id'), # ÏõêÎ≥∏ ÏöîÏ≤≠Ïùò project_id Ï†ÑÎã¨
                     'task_id': task_id,
                     'progress': training_progress[task_id]
                 }))
             else:
                 print(f"[WARN] Ïú†Ìö®ÌïòÏßÄ ÏïäÍ±∞ÎÇò ÏôÑÎ£åÎêú Task ID({task_id})Ïóê ÎåÄÌïú ÏÉÅÌÉú ÏöîÏ≤≠ ÏàòÏã†.")
        # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

        # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] 3D Í∞ùÏ≤¥ Î∂ÑÌï† Ï†ÄÏû• Ï≤òÎ¶¨ ‚ñº‚ñº‚ñº
        elif msg_type == 'save_split':
            print(f"[DEBUG] 3D Í∞ùÏ≤¥ Î∂ÑÌï† Ï†ÄÏû• ÏöîÏ≤≠ ÏàòÏã†")
            try:
                result = await self.db_save_split_element(payload)
                split_id = result['split_id']
                print(f"[DEBUG] Î∂ÑÌï† Í∞ùÏ≤¥ Ï†ÄÏû• ÏÑ±Í≥µ: {split_id}")
                print(f"[DEBUG] ÏÉùÏÑ±Îêú QuantityMembers: {result['created_qm_count']}, CostItems: {result['created_ci_count']}")
                await self.send(text_data=json.dumps({
                    'type': 'split_saved',
                    'split_id': str(split_id),
                    'raw_element_id': str(payload.get('raw_element_id')),
                    'split_part_type': payload.get('split_part_type'),
                    'created_qm_count': result['created_qm_count'],
                    'created_ci_count': result['created_ci_count'],
                    'success': True
                }))
            except Exception as e:
                print(f"[ERROR] Î∂ÑÌï† Í∞ùÏ≤¥ Ï†ÄÏû• Ïã§Ìå®: {str(e)}")
                import traceback
                traceback.print_exc()
                await self.send(text_data=json.dumps({
                    'type': 'split_save_error',
                    'error': str(e),
                    'success': False
                }))
        # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

        else:
            # ÎîîÎ≤ÑÍπÖ: Ïïå Ïàò ÏóÜÎäî Î©îÏãúÏßÄ ÌÉÄÏûÖ
            print(f"[WARNING][{self.__class__.__name__}] Ï≤òÎ¶¨ÎêòÏßÄ ÏïäÏùÄ Î©îÏãúÏßÄ Ïú†Ìòï: {msg_type}")


    async def broadcast_progress(self, event):
        # ÎîîÎ≤ÑÍπÖ: ÏßÑÌñâÎ•† Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞ ÏßÑÌñâÎ•† Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏: type='{event['data'].get('type')}'")
        await self.send(text_data=json.dumps(event['data']))
    async def broadcast_tags(self, event):
        # ÎîîÎ≤ÑÍπÖ: ÌÉúÍ∑∏ Î™©Î°ù Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÌÉúÍ∑∏ Î™©Î°ù ÏóÖÎç∞Ïù¥Ìä∏ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏ ({len(event['tags'])}Í∞ú).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': event['tags']}))
    async def broadcast_elements(self, event):
        # ÎîîÎ≤ÑÍπÖ: Í∞ùÏ≤¥ Ï†ïÎ≥¥ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Í∞ùÏ≤¥ Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏ ({len(event['elements'])}Í∞ú).")
        await self.send(text_data=json.dumps({'type': 'elements_updated', 'elements': event['elements']}))
    async def broadcast_selection(self, event):
        # ÎîîÎ≤ÑÍπÖ: ÏÑ†ÌÉù Ï†ïÎ≥¥ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] Revit/Blender ÏÑ†ÌÉù Ï†ïÎ≥¥ ÏóÖÎç∞Ïù¥Ìä∏ Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏ ({len(event['unique_ids'])}Í∞ú).")
        await self.send(text_data=json.dumps({'type': 'revit_selection_update', 'unique_ids': event['unique_ids']}))

    # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] AI ÌïôÏäµ ÏßÑÌñâÎ•† Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏ Ìï∏Îì§Îü¨ ‚ñº‚ñº‚ñº
    async def broadcast_training_progress(self, event):
        """views.pyÏóêÏÑú Ìò∏Ï∂úÎêòÏñ¥ AI ÌïôÏäµ ÏßÑÌñâÎ•†ÏùÑ ÌäπÏ†ï ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Í∑∏Î£πÏóêÍ≤å Ï†ÑÏÜ°"""
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] AI ÌïôÏäµ ÏßÑÌñâÎ•† Î∏åÎ°úÎìúÏ∫êÏä§Ìä∏ (Task ID: {event['task_id']}, Status: {event['progress']['status']}).")
        await self.send(text_data=json.dumps({
            'type': 'training_progress_update', # ÌîÑÎ°†Ìä∏ÏóîÎìúÏóêÏÑú Î∞õÏùÑ Î©îÏãúÏßÄ ÌÉÄÏûÖ
            'project_id': event['project_id'],
            'task_id': event['task_id'],
            'progress': event['progress'],
        }))
    # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

    async def send_tags_update(self, tags):
        # ÎîîÎ≤ÑÍπÖ: ÌäπÏ†ï ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÍ≤å ÌÉúÍ∑∏ Î™©Î°ù Ï†ÑÏÜ°
        print(f"  ‚û°Ô∏è [{self.__class__.__name__}] ÌòÑÏû¨ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÍ≤å ÌÉúÍ∑∏ Î™©Î°ù Ï†ÑÏÜ° ({len(tags)}Í∞ú).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': tags}))

    @database_sync_to_async
    def db_get_tags(self, project_id):
        # ÎîîÎ≤ÑÍπÖ: DBÏóêÏÑú ÌÉúÍ∑∏ Ï°∞Ìöå
        print(f"[DEBUG][DB Async][db_get_tags] Querying tags for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tags = list(project.classification_tags.all())
        print(f"[DEBUG][DB Async][db_get_tags] Found {len(tags)} tags.")
        return serialize_tags(tags)
    @database_sync_to_async
    def db_create_tag(self, project_id, name):
        if not name: return
        # ÎîîÎ≤ÑÍπÖ: DBÏóê ÌÉúÍ∑∏ ÏÉùÏÑ±
        print(f"[DEBUG][DB Async][db_create_tag] Creating tag '{name}' for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tag, created = QuantityClassificationTag.objects.get_or_create(project=project, name=name)
        print(f"[DEBUG][DB Async][db_create_tag] Tag '{name}' {'created' if created else 'already exists'}.")
    @database_sync_to_async
    def db_update_tag(self, tag_id, new_name):
        if not new_name: return
        # ÎîîÎ≤ÑÍπÖ: DBÏóêÏÑú ÌÉúÍ∑∏ ÏàòÏ†ï
        print(f"[DEBUG][DB Async][db_update_tag] Updating tag ID '{tag_id}' to name '{new_name}'")
        try:
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            tag.name = new_name; tag.save()
            print(f"[DEBUG][DB Async][db_update_tag] Tag ID '{tag_id}' updated successfully.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_update_tag] Tag ID '{tag_id}' not found.")
    @database_sync_to_async
    def db_delete_tag(self, tag_id):
        """
        ÌÉúÍ∑∏Î•º ÏÇ≠Ï†úÌïòÍ≥†, Ìï¥Îãπ ÌÉúÍ∑∏Ïóê ÏòÅÌñ•ÏùÑ Î∞õÏïòÎçò RawElementÏùò ID Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§.
        """
        # ÎîîÎ≤ÑÍπÖ: DBÏóêÏÑú ÌÉúÍ∑∏ ÏÇ≠Ï†ú
        print(f"[DEBUG][DB Async][db_delete_tag] Deleting tag ID '{tag_id}'")
        try:
            # ÏÇ≠Ï†úÌïòÍ∏∞ Ï†ÑÏóê, Ïñ¥Îñ§ Í∞ùÏ≤¥Îì§Ïù¥ Ïù¥ ÌÉúÍ∑∏Î•º Í∞ÄÏßÄÍ≥† ÏûàÏóàÎäîÏßÄ IDÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.
            tag_to_delete = QuantityClassificationTag.objects.prefetch_related('raw_elements').get(id=tag_id)
            affected_element_ids = list(tag_to_delete.raw_elements.values_list('id', flat=True))
            print(f"[DEBUG][DB Async][db_delete_tag] Found {len(affected_element_ids)} affected elements before deletion.")

            # ÌÉúÍ∑∏Î•º ÏÇ≠Ï†úÌï©ÎãàÎã§. (ManyToManyField Í¥ÄÍ≥ÑÎäî ÏûêÎèôÏúºÎ°ú Ï†ïÎ¶¨Îê©ÎãàÎã§)
            tag_to_delete.delete()
            print(f"[DEBUG][DB Async][db_delete_tag] Tag ID '{tag_id}' deleted successfully.")

            return affected_element_ids
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_delete_tag] Tag ID '{tag_id}' not found.")
            return [] # ÏÇ≠Ï†úÌï† ÌÉúÍ∑∏Í∞Ä ÏóÜÏúºÎ©¥ Îπà Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§.
        except Exception as e:
            print(f"[ERROR][DB Async][db_delete_tag] Exception during deletion: {e}")
            return []
    @database_sync_to_async
    def db_assign_tags(self, tag_id, element_ids):
        """
        ÏàòÎèôÏúºÎ°ú ÌÉúÍ∑∏Î•º Ìï†ÎãπÌï©ÎãàÎã§ (assignment_type='manual')
        """
        # ÎîîÎ≤ÑÍπÖ: DBÏóêÏÑú ÌÉúÍ∑∏ Ìï†Îãπ
        print(f"[DEBUG][DB Async][db_assign_tags] Manually assigning tag ID '{tag_id}' to {len(element_ids)} elements.")
        try:
            from connections.models import ElementClassificationAssignment
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            added_count = 0
            for element in elements_to_update:
                _, created = ElementClassificationAssignment.objects.get_or_create(
                    raw_element=element,
                    classification_tag=tag,
                    defaults={
                        'assignment_type': 'manual',
                        'assigned_by_rule': None
                    }
                )
                if created:
                    added_count += 1
            print(f"[DEBUG][DB Async][db_assign_tags] Tag assignment complete. {added_count} new manual assignments.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_assign_tags] Tag ID '{tag_id}' not found.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_assign_tags] Exception during assignment: {e}")
    @database_sync_to_async
    def db_clear_tags(self, element_ids):
        # ÎîîÎ≤ÑÍπÖ: DBÏóêÏÑú ÌÉúÍ∑∏ Ï†úÍ±∞
        print(f"[DEBUG][DB Async][db_clear_tags] Clearing tags from {len(element_ids)} elements.")
        try:
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            cleared_count = 0
            for element in elements_to_update:
                if element.classification_tags.exists():
                    element.classification_tags.clear()
                    cleared_count += 1
            print(f"[DEBUG][DB Async][db_clear_tags] Tag clearing complete. {cleared_count} elements had tags cleared.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_clear_tags] Exception during clearing: {e}")

    # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] 3D Í∞ùÏ≤¥ Î∂ÑÌï† Ï†ÄÏû• Î©îÏÑúÎìú ‚ñº‚ñº‚ñº
    @database_sync_to_async
    def db_save_split_element(self, payload):
        """
        3D Î∑∞Ïñ¥ÏóêÏÑú ÏÉùÏÑ±Îêú Î∂ÑÌï† Í∞ùÏ≤¥Î•º DBÏóê Ï†ÄÏû•

        payload Íµ¨Ï°∞:
        {
            'project_id': UUID,
            'raw_element_id': UUID,
            'parent_split_id': UUID (optional),
            'original_geometry_volume': Decimal,
            'geometry_volume': Decimal,
            'volume_ratio': Decimal,
            'split_method': 'plane' | 'sketch',
            'split_axis': 'x' | 'y' | 'z' (plane only),
            'split_position': Decimal (plane only),
            'split_part_type': 'bottom' | 'top' | 'remainder' | 'extracted',
            'geometry_data': {...},
            'sketch_data': {...} (sketch only)
        }
        """
        print(f"[DEBUG][DB Async][db_save_split_element] Saving split element...")

        try:
            # ProjectÏôÄ RawElement Í∞ÄÏ†∏Ïò§Í∏∞
            project = Project.objects.get(id=payload['project_id'])
            raw_element = RawElement.objects.get(id=payload['raw_element_id'])

            # Parent split (optional)
            parent_split = None
            if payload.get('parent_split_id'):
                parent_split = SplitElement.objects.get(id=payload['parent_split_id'])

            # SplitElement ÏÉùÏÑ±
            split_element = SplitElement.objects.create(
                project=project,
                raw_element=raw_element,
                parent_split=parent_split,
                original_geometry_volume=payload['original_geometry_volume'],
                geometry_volume=payload['geometry_volume'],
                volume_ratio=payload['volume_ratio'],
                split_method=payload['split_method'],
                split_axis=payload.get('split_axis'),  # plane only
                split_position=payload.get('split_position'),  # plane only
                split_part_type=payload['split_part_type'],
                geometry_data=payload.get('geometry_data', {}),
                sketch_data=payload.get('sketch_data', {}),
                is_active=True
            )

            print(f"[DEBUG][DB Async][db_save_split_element] Split element saved successfully:")
            print(f"  - ID: {split_element.id}")
            print(f"  - RawElement: {raw_element.element_unique_id}")
            print(f"  - Method: {split_element.split_method}")
            print(f"  - Part Type: {split_element.split_part_type}")
            print(f"  - Volume: {split_element.geometry_volume}")
            print(f"  - Ratio: {float(split_element.volume_ratio) * 100:.2f}%")

            # ‚ñº‚ñº‚ñº QuantityMemberÏôÄ CostItem Î≥µÏ†ú Î°úÏßÅ ‚ñº‚ñº‚ñº
            # 1. ÏõêÎ≥∏ QuantityMembers Ï°∞Ìöå (parent_split ÎòêÎäî raw_elementÏóêÏÑú)
            # 2. Î∂ÄÎ™® ÎåÄÎπÑ volume ratio Í≥ÑÏÇ∞
            if parent_split:
                # Î∂ÄÎ™® Î∂ÑÌï† Í∞ùÏ≤¥Ïóê Ïó∞Í≤∞Îêú QuantityMember Î≥µÏ†ú
                # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] is_active ÌïÑÌÑ∞ Ï†úÍ±∞: Ï≤´ Î≤àÏß∏ splitÏóêÏÑú ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ÎèÑ Îëê Î≤àÏß∏ splitÏóêÏÑú Î≥µÏ†ú Í∞ÄÎä• ‚ñº‚ñº‚ñº
                source_members = QuantityMember.objects.filter(
                    split_element=parent_split
                )
                # Î∂ÄÎ™® ÎåÄÎπÑ volume ratio Í≥ÑÏÇ∞
                parent_volume = float(parent_split.geometry_volume)
                parent_volume_ratio = float(split_element.geometry_volume) / parent_volume if parent_volume > 0 else 0.5

                # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] ÏïàÏ†ÑÏû•Ïπò: volume ratioÍ∞Ä 1.0ÏùÑ Ï¥àÍ≥ºÌïòÎäî Í≤ΩÏö∞ (geometry Í≥ÑÏÇ∞ Ïò§Î•ò) ‚ñº‚ñº‚ñº
                if parent_volume_ratio > 1.0:
                    print(f"[WARN][DB Async][db_save_split_element] Volume ratio exceeds 1.0! Current: {parent_volume_ratio:.6f}")
                    print(f"[WARN][DB Async][db_save_split_element] This indicates geometry calculation error in frontend")
                    print(f"[WARN][DB Async][db_save_split_element] Clamping to 1.0 to prevent quantity increase")
                    parent_volume_ratio = 1.0
                # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

                print(f"[DEBUG][DB Async][db_save_split_element] Found {source_members.count()} QMs from parent split")
                print(f"[DEBUG][DB Async][db_save_split_element] Parent volume: {parent_volume:.6f}, Current volume: {float(split_element.geometry_volume):.6f}")
                print(f"[DEBUG][DB Async][db_save_split_element] Parent volume ratio (clamped): {parent_volume_ratio:.6f} ({parent_volume_ratio * 100:.2f}%)")
            else:
                # ÏõêÎ≥∏ BIM Í∞ùÏ≤¥Ïóê Ïó∞Í≤∞Îêú QuantityMember Î≥µÏ†ú
                # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] is_active ÌïÑÌÑ∞ Ï†úÍ±∞: Ï≤´ Î≤àÏß∏ splitÏóêÏÑú ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ÎèÑ Îëê Î≤àÏß∏ splitÏóêÏÑú Î≥µÏ†ú Í∞ÄÎä• ‚ñº‚ñº‚ñº
                source_members = QuantityMember.objects.filter(
                    raw_element=raw_element,
                    split_element__isnull=True  # Î∂ÑÌï†ÎêòÏßÄ ÏïäÏùÄ ÏõêÎ≥∏Îßå
                )
                # ÏõêÎ≥∏ BIM Í∞ùÏ≤¥ ÎåÄÎπÑ volume ratioÎäî split_element.volume_ratio ÏÇ¨Ïö©
                parent_volume_ratio = float(split_element.volume_ratio)

                # ‚ñº‚ñº‚ñº [Ï∂îÍ∞Ä] ÏïàÏ†ÑÏû•Ïπò: volume ratioÍ∞Ä 1.0ÏùÑ Ï¥àÍ≥ºÌïòÎäî Í≤ΩÏö∞ ‚ñº‚ñº‚ñº
                if parent_volume_ratio > 1.0:
                    print(f"[WARN][DB Async][db_save_split_element] Volume ratio exceeds 1.0! Current: {parent_volume_ratio:.6f}")
                    print(f"[WARN][DB Async][db_save_split_element] Clamping to 1.0 to prevent quantity increase")
                    parent_volume_ratio = 1.0
                # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤

                print(f"[DEBUG][DB Async][db_save_split_element] Found {source_members.count()} QMs from raw element")
                print(f"[DEBUG][DB Async][db_save_split_element] Original BIM volume ratio (clamped): {parent_volume_ratio:.6f} ({parent_volume_ratio * 100:.2f}%)")

            created_qm_count = 0
            created_ci_count = 0

            for source_member in source_members:
                # 2. QuantityMember Î≥µÏ†ú
                new_member = QuantityMember.objects.create(
                    project=project,
                    raw_element=raw_element,
                    classification_tag=source_member.classification_tag,
                    member_mark=source_member.member_mark,
                    name=source_member.name,
                    properties=source_member.properties.copy() if source_member.properties else {},
                    mapping_expression=source_member.mapping_expression.copy() if source_member.mapping_expression else {},
                    member_mark_expression=source_member.member_mark_expression,
                    cost_code_expressions=source_member.cost_code_expressions.copy() if source_member.cost_code_expressions else [],
                    is_active=True,
                    split_element=split_element,
                    source_quantity_member=source_member
                )

                # ManyToMany Í¥ÄÍ≥Ñ Î≥µÏÇ¨
                new_member.cost_codes.set(source_member.cost_codes.all())
                new_member.space_classifications.set(source_member.space_classifications.all())
                created_qm_count += 1

                # 3. ÏõêÎ≥∏ QuantityMemberÎ•º ÎπÑÌôúÏÑ±Ìôî
                source_member.is_active = False
                source_member.save(update_fields=['is_active'])

                # 4. CostItem Î≥µÏ†ú Î∞è ÏàòÎüâ Ï†ÅÏö©
                # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] is_active ÌïÑÌÑ∞ Ï†úÍ±∞: Ï≤´ Î≤àÏß∏ splitÏóêÏÑú ÎπÑÌôúÏÑ±ÌôîÎêòÏñ¥ÎèÑ Îëê Î≤àÏß∏ splitÏóêÏÑú Î≥µÏ†ú Í∞ÄÎä• ‚ñº‚ñº‚ñº
                source_cost_items = CostItem.objects.filter(
                    quantity_member=source_member
                )

                for source_item in source_cost_items:
                    # ‚ñº‚ñº‚ñº [ÏàòÏ†ï] Î∂ÄÎ™® ÎåÄÎπÑ Ï≤¥Ï†Å ÎπÑÏú®ÏùÑ Ï†ÅÏö©Ìïú ÏàòÎüâ Í≥ÑÏÇ∞ ‚ñº‚ñº‚ñº
                    # parent_volume_ratio: ÏßÅÏ†Ñ Î∂ÄÎ™®(parent_split ÎòêÎäî raw_element) ÎåÄÎπÑ ÎπÑÏú®
                    # Ïù¥Î†áÍ≤å ÌïòÎ©¥ 2Ï∞®, 3Ï∞® Î∂ÑÌï† ÏãúÏóêÎèÑ ÏàòÎüâÏù¥ Ï†ïÌôïÌïòÍ≤å Ïú†ÏßÄÎê®
                    new_quantity = float(source_item.quantity) * parent_volume_ratio

                    new_item = CostItem.objects.create(
                        project=project,
                        quantity_member=new_member,
                        cost_code=source_item.cost_code,
                        quantity=new_quantity,
                        quantity_mapping_expression=source_item.quantity_mapping_expression.copy() if source_item.quantity_mapping_expression else {},
                        unit_price_type=source_item.unit_price_type,
                        description=source_item.description,
                        is_active=True,
                        split_element=split_element,
                        source_cost_item=source_item,
                        volume_ratio_applied=split_element.volume_ratio
                    )
                    created_ci_count += 1

                    # 5. ÏõêÎ≥∏ CostItemÏùÑ ÎπÑÌôúÏÑ±Ìôî
                    source_item.is_active = False
                    source_item.save(update_fields=['is_active'])

            print(f"[DEBUG][DB Async][db_save_split_element] Created {created_qm_count} QuantityMembers and {created_ci_count} CostItems")
            print(f"[DEBUG][DB Async][db_save_split_element] Applied parent volume ratio {parent_volume_ratio:.4f} ({parent_volume_ratio * 100:.2f}%) to all quantities")
            print(f"[DEBUG][DB Async][db_save_split_element] Note: volume_ratio (original BIM) = {float(split_element.volume_ratio):.4f}, parent_volume_ratio = {parent_volume_ratio:.4f}")
            # ‚ñ≤‚ñ≤‚ñ≤ Î≥µÏ†ú Î°úÏßÅ ÎÅù ‚ñ≤‚ñ≤‚ñ≤

            return {
                'split_id': split_element.id,
                'created_qm_count': created_qm_count,
                'created_ci_count': created_ci_count
            }

        except Project.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] Project {payload.get('project_id')} not found")
            raise Exception(f"Project {payload.get('project_id')} not found")
        except RawElement.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] RawElement {payload.get('raw_element_id')} not found")
            raise Exception(f"RawElement {payload.get('raw_element_id')} not found")
        except SplitElement.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] Parent split {payload.get('parent_split_id')} not found")
            raise Exception(f"Parent split {payload.get('parent_split_id')} not found")
        except Exception as e:
            print(f"[ERROR][DB Async][db_save_split_element] Exception during save: {e}")
            raise e
    # ‚ñ≤‚ñ≤‚ñ≤ [Ï∂îÍ∞Ä] Ïó¨Í∏∞ÍπåÏßÄ ‚ñ≤‚ñ≤‚ñ≤