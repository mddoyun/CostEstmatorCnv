# connections/consumers.py
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.db.models import F
# â–¼â–¼â–¼ [ì¶”ê°€] Count ì„í¬íŠ¸ â–¼â–¼â–¼
from django.db.models import Count
# â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
# â–¼â–¼â–¼ [ìˆ˜ì •] AIModel ì„í¬íŠ¸ ì¶”ê°€ â–¼â–¼â–¼
from .models import Project, RawElement, QuantityClassificationTag, QuantityMember, AIModel
# â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
import asyncio
# --- ë°ì´í„° ì§ë ¬í™” í—¬í¼ í•¨ìˆ˜ë“¤ ---
def serialize_tags(tags):
    # ë””ë²„ê¹…: íƒœê·¸ ì§ë ¬í™” í™•ì¸
    # print(f"[DEBUG][serialize_tags] Serializing {len(tags)} tags.") # ë„ˆë¬´ ë¹ˆë²ˆí•  ìˆ˜ ìˆì–´ ì£¼ì„ ì²˜ë¦¬
    return [{'id': str(tag.id), 'name': tag.name} for tag in tags]

@database_sync_to_async
def get_total_element_count(project_id):
    # ë””ë²„ê¹…: ì´ ê°ì²´ ìˆ˜ ì¡°íšŒ ì‹œì‘
    print(f"[DEBUG][DB Async][get_total_element_count] Querying total elements for project: {project_id}")
    try:
        count = RawElement.objects.filter(project_id=project_id).count()
        # ë””ë²„ê¹…: ì¡°íšŒ ê²°ê³¼
        print(f"[DEBUG][DB Async][get_total_element_count] Found {count} elements.")
        return count
    except Project.DoesNotExist:
        # ë””ë²„ê¹…: í”„ë¡œì íŠ¸ ì—†ìŒ
        print(f"[ERROR][DB Async][get_total_element_count] Project {project_id} does not exist.")
        return 0
    except Exception as e:
        # ë””ë²„ê¹…: ê¸°íƒ€ ì˜¤ë¥˜
        print(f"[ERROR][DB Async][get_total_element_count] Exception: {e}")
        return 0

@database_sync_to_async
def get_serialized_element_chunk(project_id, offset, limit):
    # ë””ë²„ê¹…: ì²­í¬ ì¡°íšŒ ì‹œì‘
    # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Querying chunk for project {project_id}, offset={offset}, limit={limit}") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
    try:
        element_chunk_values = list(
            RawElement.objects.filter(project_id=project_id)
            .order_by('id')
            .values('id', 'project_id', 'element_unique_id', 'geometry_volume', 'updated_at', 'raw_data')[offset:offset + limit]
        )
        if not element_chunk_values:
             # ë””ë²„ê¹…: ë¹ˆ ì²­í¬
             # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Empty chunk returned.") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
             return []
        element_ids_in_chunk = [el['id'] for el in element_chunk_values]
        tags_qs = (
            RawElement.classification_tags.through.objects
            .filter(rawelement_id__in=element_ids_in_chunk)
            .values('rawelement_id')
            .annotate(tag_name=F('quantityclassificationtag__name'))
            .values('rawelement_id', 'tag_name')
        )
        tags_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['rawelement_id']
            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_data['tag_name'])
        for element_data in element_chunk_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            # Convert Decimal to float for JSON serialization
            if element_data.get('geometry_volume') is not None:
                element_data['geometry_volume'] = float(element_data['geometry_volume'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ë””ë²„ê¹…: ì²­í¬ ì§ë ¬í™” ì™„ë£Œ
        # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Serialized {len(element_chunk_values)} elements in chunk.") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
        return element_chunk_values
    except Exception as e:
        # ë””ë²„ê¹…: ì˜¤ë¥˜ ë°œìƒ
        print(f"[ERROR][DB Async][get_serialized_element_chunk] Exception: {e}")
        return []

@database_sync_to_async
def serialize_specific_elements(element_ids):
    # ë””ë²„ê¹…: íŠ¹ì • ê°ì²´ ì§ë ¬í™” ì‹œì‘
    print(f"[DEBUG][DB Async][serialize_specific_elements] Serializing {len(element_ids)} specific elements.")
    try:
        elements_values = list(
            RawElement.objects.filter(id__in=element_ids)
            .values('id', 'project_id', 'element_unique_id', 'updated_at', 'raw_data')
        )
        if not elements_values:
            # ë””ë²„ê¹…: ëŒ€ìƒ ê°ì²´ ì—†ìŒ
             print(f"[DEBUG][DB Async][serialize_specific_elements] No elements found for the given IDs.")
             return []
        tags_qs = (
            RawElement.classification_tags.through.objects
            .filter(rawelement_id__in=element_ids)
            .values('rawelement_id')
            .annotate(tag_name=F('quantityclassificationtag__name'))
            .values('rawelement_id', 'tag_name')
        )
        tags_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['rawelement_id']
            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_data['tag_name'])
        for element_data in elements_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ë””ë²„ê¹…: ì§ë ¬í™” ì™„ë£Œ
        print(f"[DEBUG][DB Async][serialize_specific_elements] Successfully serialized {len(elements_values)} elements.")
        return elements_values
    except Exception as e:
        # ë””ë²„ê¹…: ì˜¤ë¥˜ ë°œìƒ
        print(f"[ERROR][DB Async][serialize_specific_elements] Exception: {e}")
        return []

class RevitConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.all_incoming_uids = set()
        self.project_id_for_fetch = None
        path = self.scope['path']
        if 'revit-connector' in path:
            self.group_name = 'revit_broadcast_group'
            print(f"âœ… [{self.__class__.__name__}] Revit í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ë””ë²„ê¹… ì¶”ê°€
        elif 'blender-connector' in path:
            self.group_name = 'blender_broadcast_group'
            print(f"âœ… [{self.__class__.__name__}] Blender í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ë””ë²„ê¹… ì¶”ê°€
        else:
            self.group_name = None
            print(f"âš ï¸ [{self.__class__.__name__}] ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œë¡œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œë„: {path}") # ë””ë²„ê¹… ì¶”ê°€

        if self.group_name:
            # print(f"âœ… [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ìœ„ì—ì„œ ì´ë¯¸ ì¶œë ¥
            await self.channel_layer.group_add(self.group_name, self.channel_name)
        await self.accept()

    async def disconnect(self, close_code):
        if hasattr(self, 'group_name') and self.group_name:
            print(f"âŒ [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì—ì„œ ë‚˜ê°‘ë‹ˆë‹¤ (Code: {close_code}).") # ë””ë²„ê¹… ì¶”ê°€
            await self.channel_layer.group_discard(self.group_name, self.channel_name)

    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"\nâœ‰ï¸  [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'") # ê¸°ì¡´ print ìœ ì§€

        if msg_type == 'revit_selection_response':
            # ë””ë²„ê¹…: ì„ íƒ ì‘ë‹µ ì „ë‹¬
            print(f"  â¡ï¸ [{self.__class__.__name__}] ìˆ˜ì‹ í•œ ì„ íƒ ì •ë³´({len(payload)}ê°œ ID)ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {'type': 'broadcast_selection', 'unique_ids': payload}
            )
        elif msg_type == 'fetch_progress_start':
            print("[DEBUG] 'fetch_progress_start' ìˆ˜ì‹ . ë™ê¸°í™” ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            self.all_incoming_uids.clear()

            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì—ì„œ project_idë¥¼ ê°€ì ¸ì˜¤ëŠ” ëŒ€ì‹ , ì´ë¯¸ ì €ì¥ëœ ê°’ì„ í™•ì¸í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            print(f"  - í˜„ì¬ ì„¸ì…˜ì˜ í”„ë¡œì íŠ¸ ID: {self.project_id_for_fetch}") # ê¸°ì¡´ print ìœ ì§€
            if not self.project_id_for_fetch:
                print("[CRITICAL ERROR] 'fetch_progress_start' ì‹œì ì— í”„ë¡œì íŠ¸ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ë™ê¸°í™”ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

            print(f"  - ì „ì²´ ê°ì²´ ìˆ˜: {payload.get('total_elements')}") # ê¸°ì¡´ print ìœ ì§€
            # ë””ë²„ê¹…: ì§„í–‰ ì‹œì‘ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  â¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œì‘ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        elif msg_type == 'fetch_progress_update':
            print(f"[DEBUG] 'fetch_progress_update' ìˆ˜ì‹ . ì²˜ë¦¬ëœ ê°ì²´: {payload.get('processed_count')}") # ê¸°ì¡´ print ìœ ì§€

            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì˜ project_id ëŒ€ì‹  selfì— ì €ì¥ëœ project_idë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            project_id = self.project_id_for_fetch
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

            elements_data = [json.loads(s) for s in payload.get('elements', [])]

            chunk_uids = {item['UniqueId'] for item in elements_data if item and 'UniqueId' in item}
            self.all_incoming_uids.update(chunk_uids)
            print(f"  - ì´ë²ˆ ì²­í¬ì˜ UniqueId {len(chunk_uids)}ê°œ ì¶”ê°€. í˜„ì¬ê¹Œì§€ ì´ {len(self.all_incoming_uids)}ê°œ ìˆ˜ì‹ .") # ê¸°ì¡´ print ìœ ì§€

            # ë””ë²„ê¹…: ì§„í–‰ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  â¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
            if project_id and elements_data:
                # ë””ë²„ê¹…: DB ë™ê¸°í™” ì‹œì‘
                print(f"  ğŸ”„ [{self.__class__.__name__}] ìˆ˜ì‹ í•œ {len(elements_data)}ê°œ ê°ì²´ì— ëŒ€í•œ DB ë™ê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ (Project: {project_id}).")
                await asyncio.shield(self.sync_chunk_of_elements(project_id, elements_data))

        elif msg_type == 'fetch_progress_complete':
            print("[DEBUG] 'fetch_progress_complete' ìˆ˜ì‹ . ë™ê¸°í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ê³  ì‚­ì œ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            if self.project_id_for_fetch:
                # ë””ë²„ê¹…: ì‚­ì œ ì‘ì—… ì‹œì‘
                print(f"  ğŸ—‘ï¸ [{self.__class__.__name__}] ì˜¤ë˜ëœ ê°ì²´ ì‚­ì œ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤ (Project: {self.project_id_for_fetch}).")
                await cleanup_old_elements(self.project_id_for_fetch, self.all_incoming_uids)
            else:
                print("[WARNING] 'project_id_for_fetch'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‚­ì œ ì‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

            # ë””ë²„ê¹…: ì™„ë£Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  â¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        else:
            print(f"[WARNING] ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ ìœ í˜•ì…ë‹ˆë‹¤: {msg_type}") # ê¸°ì¡´ print ìœ ì§€

    async def send_command(self, event):
        command_data = event['command_data']

        # â–¼â–¼â–¼ [ì¶”ê°€] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ëª…ë ¹ì¼ ê²½ìš°, project_idë¥¼ ë¯¸ë¦¬ ì €ì¥í•©ë‹ˆë‹¤. â–¼â–¼â–¼
        if command_data.get('command') == 'fetch_all_elements_chunked':
            project_id = command_data.get('project_id')
            self.project_id_for_fetch = project_id
            print(f"ğŸš€ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì„¸ì…˜ ì‹œì‘. Project ID '{project_id}'ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

        print(f"â¡ï¸  [{self.__class__.__name__}] '{self.group_name}' ê·¸ë£¹ì˜ í´ë¼ì´ì–¸íŠ¸ë¡œ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤: {command_data.get('command')}") # ê¸°ì¡´ print ìœ ì§€
        try: # ë””ë²„ê¹…: send ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì¶”ê°€
            await self.send(text_data=json.dumps(command_data))
        except Exception as e:
            print(f"[ERROR][{self.__class__.__name__}] Failed to send command to client: {e}")


    @database_sync_to_async
    def sync_chunk_of_elements(self, project_id, parsed_data):
        print(f"  [DB Sync] ì²­í¬ ë™ê¸°í™” ì‹œì‘: {len(parsed_data)}ê°œ ê°ì²´") # ê¸°ì¡´ print ìœ ì§€
        try:
            project = Project.objects.get(id=project_id)
            uids_in_chunk = [item['UniqueId'] for item in parsed_data if item and 'UniqueId' in item]
            existing_elements_map = {el.element_unique_id: el for el in project.raw_elements.filter(element_unique_id__in=uids_in_chunk)}
            print(f"    - DBì—ì„œ ê¸°ì¡´ ê°ì²´ {len(existing_elements_map)}ê°œ ì°¾ìŒ.") # ë””ë²„ê¹… ì¶”ê°€

            to_update, to_create = [], []
            for item in parsed_data:
                if not item or 'UniqueId' not in item: continue
                uid = item['UniqueId']
                if uid in existing_elements_map:
                    elem = existing_elements_map[uid]
                    # [ê°œì„ ] raw_dataê°€ ì‹¤ì œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸ í›„ ì—…ë°ì´íŠ¸ ëª©ë¡ì— ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
                    if elem.raw_data != item:
                        elem.raw_data = item
                        to_update.append(elem)
                else:
                    to_create.append(RawElement(project=project, element_unique_id=uid, raw_data=item))

            if to_update:
                updated_ids = [el.id for el in to_update] # ë””ë²„ê¹…ìš©
                RawElement.objects.bulk_update(to_update, ['raw_data'])
                print(f"    - {len(to_update)}ê°œ ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ. (IDs: {updated_ids[:5]}...)") # ê¸°ì¡´ print ìœ ì§€ (ID ì¶”ê°€)

                # Geometry volume ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                updated_with_volume = []
                for elem in to_update:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        updated_with_volume.append(elem)
                if updated_with_volume:
                    RawElement.objects.bulk_update(updated_with_volume, ['geometry_volume'])
                    print(f"    - {len(updated_with_volume)}ê°œ ê°ì²´ì˜ Geometry volume ê³„ì‚° ì™„ë£Œ.")

            if to_create:
                created_objs = RawElement.objects.bulk_create(to_create, ignore_conflicts=True)
                print(f"    - {len(created_objs)}ê°œ ê°ì²´ ìƒˆë¡œ ìƒì„± ì™„ë£Œ.") # ê¸°ì¡´ print ìœ ì§€ (ì‹¤ì œ ìƒì„±ëœ ìˆ˜ ì‚¬ìš©)

                # Geometry volume ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                created_with_volume = []
                for elem in created_objs:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        created_with_volume.append(elem)
                if created_with_volume:
                    RawElement.objects.bulk_update(created_with_volume, ['geometry_volume'])
                    print(f"    - {len(created_with_volume)}ê°œ ê°ì²´ì˜ Geometry volume ê³„ì‚° ì™„ë£Œ.")

        except Exception as e:
            print(f"[ERROR] sync_chunk_of_elements DB ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ê¸°ì¡´ print ìœ ì§€

@database_sync_to_async
def cleanup_old_elements(project_id, incoming_uids):
    print(f"  [DB Cleanup] ì‚­ì œ ì‘ì—… ì‹œì‘ (Project ID: {project_id})") # ê¸°ì¡´ print ìœ ì§€
    try:
        project = Project.objects.get(id=project_id)

        # [ê°œì„ ] QuerySet ì‚¬ìš© ìµœì í™” (values_list ëŒ€ì‹  set ì§ì ‘ ì‚¬ìš©)
        db_uids = set(project.raw_elements.values_list('element_unique_id', flat=True))
        print(f"    - í˜„ì¬ DBì— ì¡´ì¬í•˜ëŠ” UniqueId ìˆ˜: {len(db_uids)}") # ê¸°ì¡´ print ìœ ì§€

        incoming_uids_set = set(incoming_uids)
        print(f"    - ì´ë²ˆ ë™ê¸°í™”ì—ì„œ ë°›ì€ UniqueId ìˆ˜: {len(incoming_uids_set)}") # ê¸°ì¡´ print ìœ ì§€

        to_delete_uids = db_uids - incoming_uids_set
        print(f"    - ì‚­ì œ ëŒ€ìƒ UniqueId ìˆ˜: {len(to_delete_uids)}") # ê¸°ì¡´ print ìœ ì§€

        if to_delete_uids:
            print(f"    - ì‚­ì œ ëŒ€ìƒ ID (ìµœëŒ€ 10ê°œ í‘œì‹œ): {list(to_delete_uids)[:10]}") # ê¸°ì¡´ print ìœ ì§€

            # â–¼â–¼â–¼ [ì¶”ê°€] RawElementë¥¼ ì‚­ì œí•˜ê¸° ì „ì—, ì—°ê´€ëœ QuantityMemberë¥¼ ë¨¼ì € ì‚­ì œí•˜ëŠ” ë¡œì§ì…ë‹ˆë‹¤. â–¼â–¼â–¼
            print(f"    - [QuantityMember Cleanup] ì‚­ì œë  RawElementì™€ ì—°ê´€ëœ ìˆ˜ëŸ‰ì‚°ì¶œë¶€ì¬ë¥¼ ë¨¼ì € ì‚­ì œí•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

            # raw_element í•„ë“œê°€ nullì´ ì•„ë‹Œ(ì¦‰, BIM ê°ì²´ì™€ ì—°ê³„ëœ) ìˆ˜ëŸ‰ì‚°ì¶œë¶€ì¬ ì¤‘ì—ì„œ
            # ì‚­ì œë  RawElementì˜ unique_idë¥¼ ê°€ì§„ ë¶€ì¬ë“¤ì„ ì°¾ì•„ ì‚­ì œí•©ë‹ˆë‹¤.
            deletable_members = QuantityMember.objects.filter(
                project=project,
                raw_element__element_unique_id__in=to_delete_uids
            )

            member_deleted_count, deleted_details = deletable_members.delete() # ìƒì„¸ ì •ë³´ ë°›ì„ ìˆ˜ ìˆìŒ
            print(f"    - [QuantityMember Cleanup] {member_deleted_count}ê°œì˜ ì—°ê´€ëœ ìˆ˜ëŸ‰ì‚°ì¶œë¶€ì¬ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. Details: {deleted_details}") # ê¸°ì¡´ print ìœ ì§€ (ìƒì„¸ ì •ë³´ ì¶”ê°€)
            # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

            deleted_count, deleted_raw_details = project.raw_elements.filter(element_unique_id__in=to_delete_uids).delete()
            print(f"    - DBì—ì„œ {deleted_count}ê°œì˜ ì˜¤ë˜ëœ RawElement ê°ì²´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. Details: {deleted_raw_details}") # ê¸°ì¡´ print ìœ ì§€ (ìƒì„¸ ì •ë³´ ì¶”ê°€)
        else:
            print("    - ì‚­ì œí•  ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

    except Exception as e:
        print(f"[ERROR] cleanup_old_elements DB ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ê¸°ì¡´ print ìœ ì§€

class FrontendConsumer(AsyncWebsocketConsumer):
    frontend_group_name = 'frontend_group'
    async def connect(self):
        # ë””ë²„ê¹…: í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°
        print(f"âœ… [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ê°€ '{self.frontend_group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.")
        await self.channel_layer.group_add(self.frontend_group_name, self.channel_name); await self.accept()
    async def disconnect(self, close_code):
        # ë””ë²„ê¹…: í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²° í•´ì œ
        print(f"âŒ [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ê°€ '{self.frontend_group_name}' ê·¸ë£¹ì—ì„œ ë‚˜ê°‘ë‹ˆë‹¤ (Code: {close_code}).")
        await self.channel_layer.group_discard(self.frontend_group_name, self.channel_name)


    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"âœ‰ï¸ [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì €ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'") # ê¸°ì¡´ print ìœ ì§€

        if msg_type == 'command_to_client':
            target_group = payload.pop('target_group', 'revit_broadcast_group')
            print(f"   â¡ï¸  '{target_group}' ê·¸ë£¹ìœ¼ë¡œ ëª…ë ¹ì„ ì „ë‹¬í•©ë‹ˆë‹¤: {payload}") # ê¸°ì¡´ print ìœ ì§€
            await self.channel_layer.group_send(target_group, {'type': 'send.command', 'command_data': payload})

        # â–¼â–¼â–¼ [ìˆ˜ì •] get_all_elements ë©”ì‹œì§€ ì²˜ë¦¬ ë¶€ë¶„ì— printë¬¸ ì¶”ê°€ â–¼â–¼â–¼
        elif msg_type == 'get_all_elements':
            project_id = payload.get('project_id')
            if project_id:
                print(f"\n[DEBUG] í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° '{project_id}' í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ê°ì²´ ë°ì´í„° ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
                total_elements = await get_total_element_count(project_id)
                print(f"[DEBUG] ì´ {total_elements}ê°œì˜ ê°ì²´ë¥¼ ì „ì†¡ ì‹œì‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
                await self.send(text_data=json.dumps({'type': 'revit_data_start', 'payload': {'total': total_elements}}))

                CHUNK_SIZE = 1000 # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í›„ ì¡°ì ˆ ê°€ëŠ¥
                sent_count = 0
                for offset in range(0, total_elements, CHUNK_SIZE):
                    chunk = await get_serialized_element_chunk(project_id, offset, CHUNK_SIZE)
                    if chunk:
                        await self.send(text_data=json.dumps({'type': 'revit_data_chunk', 'payload': chunk}))
                        sent_count += len(chunk)
                        # ë””ë²„ê¹…: ì²­í¬ ì „ì†¡ ë¡œê·¸ (ë„ˆë¬´ ë¹ˆë²ˆí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì¡°ê±´ë¶€ ì¶œë ¥ ê³ ë ¤)
                        # print(f"    [WebSocket Send] Sent chunk: {offset+1}-{sent_count}/{total_elements}")
                    await asyncio.sleep(0.01) # ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

                print(f"[DEBUG] {sent_count}ê°œ ê°ì²´ ì „ì†¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤ (ì´ {total_elements}ê°œ ëŒ€ìƒ).") # ê¸°ì¡´ print ìœ ì§€ (ì‹¤ì œ ì „ì†¡ëœ ìˆ˜ í¬í•¨)
                await self.send(text_data=json.dumps({'type': 'revit_data_complete'}))
        # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ì…ë‹ˆë‹¤. â–²â–²â–²

        elif msg_type == 'get_tags':
            project_id = payload.get('project_id')
            if project_id:
                # ë””ë²„ê¹…: íƒœê·¸ ìš”ì²­
                print(f"[DEBUG] '{project_id}' í”„ë¡œì íŠ¸ì˜ íƒœê·¸ ëª©ë¡ ìš”ì²­ ìˆ˜ì‹ .")
                tags = await self.db_get_tags(project_id)
                await self.send_tags_update(tags)
        
        elif msg_type in ['create_tag', 'update_tag']:
            project_id = payload.get('project_id')
            if not project_id: return
            if msg_type == 'create_tag':
                # ë””ë²„ê¹…: íƒœê·¸ ìƒì„± ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ìƒì„± ìš”ì²­: name='{payload.get('name')}'")
                await self.db_create_tag(project_id, payload.get('name'))
            elif msg_type == 'update_tag':
                # ë””ë²„ê¹…: íƒœê·¸ ìˆ˜ì • ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ìˆ˜ì • ìš”ì²­: id='{payload.get('tag_id')}', new_name='{payload.get('new_name')}'")
                await self.db_update_tag(payload.get('tag_id'), payload.get('new_name'))

            # ìƒì„± ë˜ëŠ” ìˆ˜ì • í›„ì—ëŠ” íƒœê·¸ ëª©ë¡ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            # ë””ë²„ê¹…: íƒœê·¸ ëª©ë¡ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  â¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ íƒœê·¸ ëª©ë¡ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

        elif msg_type == 'delete_tag':
            project_id = payload.get('project_id')
            tag_id = payload.get('tag_id')
            if not all([project_id, tag_id]): return
            # ë””ë²„ê¹…: íƒœê·¸ ì‚­ì œ ìš”ì²­
            print(f"[DEBUG] íƒœê·¸ ì‚­ì œ ìš”ì²­: id='{tag_id}'")

            # 1. íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , ì˜í–¥ì„ ë°›ì•˜ë˜ elementë“¤ì˜ ID ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            affected_ids = await self.db_delete_tag(tag_id)
            # ë””ë²„ê¹…: ì‚­ì œ ê²°ê³¼ ë° ì˜í–¥ ë°›ì€ ê°ì²´ ID
            print(f"  - íƒœê·¸ ì‚­ì œ ì™„ë£Œ. ì˜í–¥ ë°›ì€ ê°ì²´ ìˆ˜: {len(affected_ids)}")

            # 2. ë³€ê²½ëœ ì „ì²´ íƒœê·¸ ëª©ë¡ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            print(f"  â¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ íƒœê·¸ ëª©ë¡ì„ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

            # 3. ë§Œì•½ ì˜í–¥ì„ ë°›ì€ elementê°€ ìˆì—ˆë‹¤ë©´, í•´ë‹¹ elementë“¤ì˜ ìµœì‹  ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            if affected_ids:
                elements = await serialize_specific_elements(affected_ids)
                print(f"  â¡ï¸ [{self.__class__.__name__}] ì˜í–¥ ë°›ì€ {len(elements)}ê°œ ê°ì²´ì˜ ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
                await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        elif msg_type in ['assign_tags', 'clear_tags']:
            element_ids = payload.get('element_ids')
            if msg_type == 'assign_tags':
                # ë””ë²„ê¹…: íƒœê·¸ í• ë‹¹ ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ í• ë‹¹ ìš”ì²­: tag_id='{payload.get('tag_id')}', elements={len(element_ids)}ê°œ")
                await self.db_assign_tags(payload.get('tag_id'), element_ids)
            elif msg_type == 'clear_tags':
                # ë””ë²„ê¹…: íƒœê·¸ ì œê±° ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ì œê±° ìš”ì²­: elements={len(element_ids)}ê°œ")
                await self.db_clear_tags(element_ids)
            elements = await serialize_specific_elements(element_ids)
            # ë””ë²„ê¹…: ê°ì²´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  â¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ {len(elements)}ê°œ ê°ì²´ ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        # â–¼â–¼â–¼ [ì¶”ê°€] AI í•™ìŠµ ìƒíƒœ í´ë§ ìš”ì²­ ì²˜ë¦¬ â–¼â–¼â–¼
        elif msg_type == 'get_training_status':
             task_id = payload.get('task_id')
             if task_id and task_id in training_progress:
                 print(f"[DEBUG] AI í•™ìŠµ ìƒíƒœ ìš”ì²­ ìˆ˜ì‹  (Task ID: {task_id}). í˜„ì¬ ìƒíƒœ ì „ì†¡.")
                 await self.send(text_data=json.dumps({
                     'type': 'training_progress_update',
                     'project_id': payload.get('project_id'), # ì›ë³¸ ìš”ì²­ì˜ project_id ì „ë‹¬
                     'task_id': task_id,
                     'progress': training_progress[task_id]
                 }))
             else:
                 print(f"[WARN] ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì™„ë£Œëœ Task ID({task_id})ì— ëŒ€í•œ ìƒíƒœ ìš”ì²­ ìˆ˜ì‹ .")
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
        else:
            # ë””ë²„ê¹…: ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ì…
            print(f"[WARNING][{self.__class__.__name__}] ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ ìœ í˜•: {msg_type}")


    async def broadcast_progress(self, event):
        # ë””ë²„ê¹…: ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  â¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸: type='{event['data'].get('type')}'")
        await self.send(text_data=json.dumps(event['data']))
    async def broadcast_tags(self, event):
        # ë””ë²„ê¹…: íƒœê·¸ ëª©ë¡ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  â¡ï¸ [{self.__class__.__name__}] íƒœê·¸ ëª©ë¡ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['tags'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': event['tags']}))
    async def broadcast_elements(self, event):
        # ë””ë²„ê¹…: ê°ì²´ ì •ë³´ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  â¡ï¸ [{self.__class__.__name__}] ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['elements'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'elements_updated', 'elements': event['elements']}))
    async def broadcast_selection(self, event):
        # ë””ë²„ê¹…: ì„ íƒ ì •ë³´ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  â¡ï¸ [{self.__class__.__name__}] Revit/Blender ì„ íƒ ì •ë³´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['unique_ids'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'revit_selection_update', 'unique_ids': event['unique_ids']}))

    # â–¼â–¼â–¼ [ì¶”ê°€] AI í•™ìŠµ ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸ í•¸ë“¤ëŸ¬ â–¼â–¼â–¼
    async def broadcast_training_progress(self, event):
        """views.pyì—ì„œ í˜¸ì¶œë˜ì–´ AI í•™ìŠµ ì§„í–‰ë¥ ì„ íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ ê·¸ë£¹ì—ê²Œ ì „ì†¡"""
        print(f"  â¡ï¸ [{self.__class__.__name__}] AI í•™ìŠµ ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸ (Task ID: {event['task_id']}, Status: {event['progress']['status']}).")
        await self.send(text_data=json.dumps({
            'type': 'training_progress_update', # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì„ ë©”ì‹œì§€ íƒ€ì…
            'project_id': event['project_id'],
            'task_id': event['task_id'],
            'progress': event['progress'],
        }))
    # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

    async def send_tags_update(self, tags):
        # ë””ë²„ê¹…: íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ì—ê²Œ íƒœê·¸ ëª©ë¡ ì „ì†¡
        print(f"  â¡ï¸ [{self.__class__.__name__}] í˜„ì¬ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ íƒœê·¸ ëª©ë¡ ì „ì†¡ ({len(tags)}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': tags}))

    @database_sync_to_async
    def db_get_tags(self, project_id):
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì¡°íšŒ
        print(f"[DEBUG][DB Async][db_get_tags] Querying tags for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tags = list(project.classification_tags.all())
        print(f"[DEBUG][DB Async][db_get_tags] Found {len(tags)} tags.")
        return serialize_tags(tags)
    @database_sync_to_async
    def db_create_tag(self, project_id, name):
        if not name: return
        # ë””ë²„ê¹…: DBì— íƒœê·¸ ìƒì„±
        print(f"[DEBUG][DB Async][db_create_tag] Creating tag '{name}' for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tag, created = QuantityClassificationTag.objects.get_or_create(project=project, name=name)
        print(f"[DEBUG][DB Async][db_create_tag] Tag '{name}' {'created' if created else 'already exists'}.")
    @database_sync_to_async
    def db_update_tag(self, tag_id, new_name):
        if not new_name: return
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ìˆ˜ì •
        print(f"[DEBUG][DB Async][db_update_tag] Updating tag ID '{tag_id}' to name '{new_name}'")
        try:
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            tag.name = new_name; tag.save()
            print(f"[DEBUG][DB Async][db_update_tag] Tag ID '{tag_id}' updated successfully.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_update_tag] Tag ID '{tag_id}' not found.")
    @database_sync_to_async
    def db_delete_tag(self, tag_id):
        """
        íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , í•´ë‹¹ íƒœê·¸ì— ì˜í–¥ì„ ë°›ì•˜ë˜ RawElementì˜ ID ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì‚­ì œ
        print(f"[DEBUG][DB Async][db_delete_tag] Deleting tag ID '{tag_id}'")
        try:
            # ì‚­ì œí•˜ê¸° ì „ì—, ì–´ë–¤ ê°ì²´ë“¤ì´ ì´ íƒœê·¸ë¥¼ ê°€ì§€ê³  ìˆì—ˆëŠ”ì§€ IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            tag_to_delete = QuantityClassificationTag.objects.prefetch_related('raw_elements').get(id=tag_id)
            affected_element_ids = list(tag_to_delete.raw_elements.values_list('id', flat=True))
            print(f"[DEBUG][DB Async][db_delete_tag] Found {len(affected_element_ids)} affected elements before deletion.")

            # íƒœê·¸ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. (ManyToManyField ê´€ê³„ëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤)
            tag_to_delete.delete()
            print(f"[DEBUG][DB Async][db_delete_tag] Tag ID '{tag_id}' deleted successfully.")

            return affected_element_ids
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_delete_tag] Tag ID '{tag_id}' not found.")
            return [] # ì‚­ì œí•  íƒœê·¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        except Exception as e:
            print(f"[ERROR][DB Async][db_delete_tag] Exception during deletion: {e}")
            return []
    @database_sync_to_async
    def db_assign_tags(self, tag_id, element_ids):
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ í• ë‹¹
        print(f"[DEBUG][DB Async][db_assign_tags] Assigning tag ID '{tag_id}' to {len(element_ids)} elements.")
        try:
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            added_count = 0
            for element in elements_to_update:
                _, created = element.classification_tags.through.objects.get_or_create(rawelement=element, quantityclassificationtag=tag)
                if created: added_count += 1
            print(f"[DEBUG][DB Async][db_assign_tags] Tag assignment complete. {added_count} new assignments.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_assign_tags] Tag ID '{tag_id}' not found.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_assign_tags] Exception during assignment: {e}")
    @database_sync_to_async
    def db_clear_tags(self, element_ids):
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì œê±°
        print(f"[DEBUG][DB Async][db_clear_tags] Clearing tags from {len(element_ids)} elements.")
        try:
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            cleared_count = 0
            for element in elements_to_update:
                if element.classification_tags.exists():
                    element.classification_tags.clear()
                    cleared_count += 1
            print(f"[DEBUG][DB Async][db_clear_tags] Tag clearing complete. {cleared_count} elements had tags cleared.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_clear_tags] Exception during clearing: {e}")