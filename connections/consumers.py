# connections/consumers.py
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.db.models import F
# â–¼â–¼â–¼ [ì¶”ê°€] Count ìž„í¬íŠ¸ â–¼â–¼â–¼
from django.db.models import Count
# â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
# â–¼â–¼â–¼ [ìˆ˜ì •] AIModel, SplitElement, CostItem ìž„í¬íŠ¸ ì¶”ê°€ â–¼â–¼â–¼
from .models import Project, RawElement, QuantityClassificationTag, QuantityMember, AIModel, SplitElement, CostItem
# â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
import asyncio

# --- ë°ì´í„° í‰íƒ„í™” í—¬í¼ í•¨ìˆ˜ ---
def flatten_bim_data(element_data):
    """
    BIM ë„êµ¬ì—ì„œ ì „ì†¡í•œ ë°ì´í„°ë¥¼ í‰íƒ„í™”í•˜ì—¬ ê³„ì¸µì  í•„ë“œëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ê³ ì • í•„ë“œ (í‰íƒ„í™”í•˜ì§€ ì•ŠìŒ):
    - Name, IfcClass, ElementId, UniqueId (ê¸°ë³¸ ì‹ë³„ìž)
    - System (ì›¹ ì‹œìŠ¤í…œ ì†ì„± - Geometry í¬í•¨)

    ë™ì  í•„ë“œ (í‰íƒ„í™”):
    - BIM ë„êµ¬ì—ì„œ ë³´ë‚¸ ëª¨ë“  ì¤‘ì²© êµ¬ì¡°ë¥¼ ìž¬ê·€ì ìœ¼ë¡œ í‰íƒ„í™”
    - ì˜ˆ: Attributes.Description, Parameters.Height, PropertySet.Pset_WallCommon__IsExternal
    """
    flattened = {}

    # í‰íƒ„í™”í•˜ì§€ ì•Šì„ ê³ ì • í•„ë“œë“¤
    FIXED_FIELDS = {'Name', 'IfcClass', 'ElementId', 'UniqueId', 'System'}

    def flatten_dict(data, prefix=""):
        """ìž¬ê·€ì ìœ¼ë¡œ ë”•ì…”ë„ˆë¦¬ë¥¼ í‰íƒ„í™”"""
        for key, value in data.items():
            new_key = f"{prefix}.{key}" if prefix else key

            # GeometryëŠ” í‰íƒ„í™”í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ìœ ì§€ (ë Œë”ë§ìš©)
            if key == 'Geometry' and isinstance(value, dict):
                flattened[new_key] = value
                continue

            if isinstance(value, dict):
                # ë”•ì…”ë„ˆë¦¬ë©´ ìž¬ê·€ì ìœ¼ë¡œ í‰íƒ„í™”
                flatten_dict(value, new_key)
            elif isinstance(value, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°, JSON ë¬¸ìžì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ìž¥
                flattened[new_key] = json.dumps(value)
            else:
                # ìµœì¢… ê°’ì— ë„ë‹¬
                flattened[new_key] = value

    # ê³ ì • í•„ë“œê°€ ì•„ë‹Œ ëª¨ë“  í•„ë“œë¥¼ ë™ì ìœ¼ë¡œ í‰íƒ„í™”
    for key, value in element_data.items():
        if key not in FIXED_FIELDS and isinstance(value, dict):
            flatten_dict(value, key)

    return flattened

# --- ë°ì´í„° ì§ë ¬í™” í—¬í¼ í•¨ìˆ˜ë“¤ ---
def serialize_tags(tags):
    # ë””ë²„ê¹…: íƒœê·¸ ì§ë ¬í™” í™•ì¸
    # print(f"[DEBUG][serialize_tags] Serializing {len(tags)} tags.") # ë„ˆë¬´ ë¹ˆë²ˆí•  ìˆ˜ ìžˆì–´ ì£¼ì„ ì²˜ë¦¬
    return [{'id': str(tag.id), 'name': tag.name} for tag in tags]

@database_sync_to_async
def get_total_element_count(project_id):
    # ë””ë²„ê¹…: ì´ ê°ì²´ ìˆ˜ ì¡°íšŒ ì‹œìž‘
    print(f"[DEBUG][DB Async][get_total_element_count] Querying total elements for project: {project_id}")
    try:
        count = RawElement.objects.filter(project_id=project_id).count()
        # ë””ë²„ê¹…: ì¡°íšŒ ê²°ê³¼
        print(f"[DEBUG][DB Async][get_total_element_count] Found {count} elements.")
        return count
    except Project.DoesNotExist:
        # ë””ë²„ê¹…: í”„ë¡œì íŠ¸ ì—†ìŒ
        print(f"[ERROR][DB Async][get_total_element_count] Project {project_id} does not exist.")
        return 0
    except Exception as e:
        # ë””ë²„ê¹…: ê¸°íƒ€ ì˜¤ë¥˜
        print(f"[ERROR][DB Async][get_total_element_count] Exception: {e}")
        return 0

@database_sync_to_async
def get_serialized_element_chunk(project_id, offset, limit):
    # ë””ë²„ê¹…: ì²­í¬ ì¡°íšŒ ì‹œìž‘
    # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Querying chunk for project {project_id}, offset={offset}, limit={limit}") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
    try:
        element_chunk_values = list(
            RawElement.objects.filter(project_id=project_id)
            .order_by('id')
            .values('id', 'project_id', 'element_unique_id', 'geometry_volume', 'updated_at', 'raw_data')[offset:offset + limit]
        )
        if not element_chunk_values:
             # ë””ë²„ê¹…: ë¹ˆ ì²­í¬
             # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Empty chunk returned.") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
             return []
        element_ids_in_chunk = [el['id'] for el in element_chunk_values]
        # ElementClassificationAssignment ëª¨ë¸ import
        from connections.models import ElementClassificationAssignment

        # íƒœê·¸ í• ë‹¹ ì •ë³´ ì¡°íšŒ (assignment_type í¬í•¨)
        tags_qs = (
            ElementClassificationAssignment.objects
            .filter(raw_element_id__in=element_ids_in_chunk)
            .select_related('classification_tag')
            .values('raw_element_id', 'classification_tag__name', 'assignment_type')
        )
        tags_by_element_id = {}
        tag_details_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['raw_element_id']
            tag_name = tag_data['classification_tag__name']
            assignment_type = tag_data['assignment_type']

            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
                tag_details_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_name)
            tag_details_by_element_id[el_id].append({
                'name': tag_name,
                'assignment_type': assignment_type
            })

        for element_data in element_chunk_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['classification_tags_details'] = tag_details_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            # Convert Decimal to float for JSON serialization
            if element_data.get('geometry_volume') is not None:
                element_data['geometry_volume'] = float(element_data['geometry_volume'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ë””ë²„ê¹…: ì²­í¬ ì§ë ¬í™” ì™„ë£Œ
        # print(f"[DEBUG][DB Async][get_serialized_element_chunk] Serialized {len(element_chunk_values)} elements in chunk.") # ë„ˆë¬´ ë¹ˆë²ˆí•˜ì—¬ ì£¼ì„ ì²˜ë¦¬
        return element_chunk_values
    except Exception as e:
        # ë””ë²„ê¹…: ì˜¤ë¥˜ ë°œìƒ
        print(f"[ERROR][DB Async][get_serialized_element_chunk] Exception: {e}")
        return []

@database_sync_to_async
def serialize_specific_elements(element_ids):
    # ë””ë²„ê¹…: íŠ¹ì • ê°ì²´ ì§ë ¬í™” ì‹œìž‘
    print(f"[DEBUG][DB Async][serialize_specific_elements] Serializing {len(element_ids)} specific elements.")
    try:
        elements_values = list(
            RawElement.objects.filter(id__in=element_ids)
            .values('id', 'project_id', 'element_unique_id', 'updated_at', 'raw_data')
        )
        if not elements_values:
            # ë””ë²„ê¹…: ëŒ€ìƒ ê°ì²´ ì—†ìŒ
             print(f"[DEBUG][DB Async][serialize_specific_elements] No elements found for the given IDs.")
             return []
        # ElementClassificationAssignment ëª¨ë¸ import
        from connections.models import ElementClassificationAssignment

        # íƒœê·¸ í• ë‹¹ ì •ë³´ ì¡°íšŒ (assignment_type í¬í•¨)
        tags_qs = (
            ElementClassificationAssignment.objects
            .filter(raw_element_id__in=element_ids)
            .select_related('classification_tag')
            .values('raw_element_id', 'classification_tag__name', 'assignment_type')
        )
        tags_by_element_id = {}
        tag_details_by_element_id = {}
        for tag_data in tags_qs:
            el_id = tag_data['raw_element_id']
            tag_name = tag_data['classification_tag__name']
            assignment_type = tag_data['assignment_type']

            if el_id not in tags_by_element_id:
                tags_by_element_id[el_id] = []
                tag_details_by_element_id[el_id] = []
            tags_by_element_id[el_id].append(tag_name)
            tag_details_by_element_id[el_id].append({
                'name': tag_name,
                'assignment_type': assignment_type
            })

        for element_data in elements_values:
            element_id = element_data['id']
            element_data['classification_tags'] = tags_by_element_id.get(element_id, [])
            element_data['classification_tags_details'] = tag_details_by_element_id.get(element_id, [])
            element_data['id'] = str(element_id)
            element_data['project_id'] = str(element_data['project_id'])
            element_data['updated_at'] = element_data['updated_at'].isoformat()
        # ë””ë²„ê¹…: ì§ë ¬í™” ì™„ë£Œ
        print(f"[DEBUG][DB Async][serialize_specific_elements] Successfully serialized {len(elements_values)} elements.")
        return elements_values
    except Exception as e:
        # ë””ë²„ê¹…: ì˜¤ë¥˜ ë°œìƒ
        print(f"[ERROR][DB Async][serialize_specific_elements] Exception: {e}")
        return []

@database_sync_to_async
def get_split_elements_for_project(project_id):
    """
    í”„ë¡œì íŠ¸ì˜ ëª¨ë“  í™œì„± ë¶„í•  ê°ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.

    Returns:
        tuple: (split_elements_list, raw_element_ids_with_splits_set)
        - split_elements_list: ë¶„í•  ê°ì²´ ëª©ë¡ (ì§ë ¬í™”ë¨)
        - raw_element_ids_with_splits_set: ë¶„í• ì´ ìžˆëŠ” RawElement ID ëª©ë¡ (set)
    """
    print(f"[DEBUG][DB Async][get_split_elements_for_project] Querying split elements for project: {project_id}")

    try:
        # í™œì„± ë¶„í•  ê°ì²´ ì¡°íšŒ
        split_elements = SplitElement.objects.filter(
            project_id=project_id,
            is_active=True
        ).select_related('raw_element').values(
            'id',
            'raw_element_id',
            'parent_split_id',
            'original_geometry_volume',
            'geometry_volume',
            'volume_ratio',
            'split_method',
            'split_axis',
            'split_position',
            'split_part_type',
            'geometry_data',
            'sketch_data',
            'metadata',
            'created_at',
            'updated_at'
        )

        split_elements_list = list(split_elements)

        # ë¶„í• ì´ ìžˆëŠ” RawElement IDë“¤ì„ ìˆ˜ì§‘
        raw_element_ids_with_splits = set()

        # ì§ë ¬í™” ë° RawElement ID ìˆ˜ì§‘
        for split_data in split_elements_list:
            # UUIDë¥¼ ë¬¸ìžì—´ë¡œ ë³€í™˜
            split_data['id'] = str(split_data['id'])
            split_data['raw_element_id'] = str(split_data['raw_element_id'])

            # ë¶„í• ì´ ìžˆëŠ” RawElement ID ì¶”ê°€
            raw_element_ids_with_splits.add(split_data['raw_element_id'])

            if split_data.get('parent_split_id'):
                split_data['parent_split_id'] = str(split_data['parent_split_id'])

            # Decimalì„ floatë¡œ ë³€í™˜
            if split_data.get('original_geometry_volume') is not None:
                split_data['original_geometry_volume'] = float(split_data['original_geometry_volume'])
            if split_data.get('geometry_volume') is not None:
                split_data['geometry_volume'] = float(split_data['geometry_volume'])
            if split_data.get('volume_ratio') is not None:
                split_data['volume_ratio'] = float(split_data['volume_ratio'])
            if split_data.get('split_position') is not None:
                split_data['split_position'] = float(split_data['split_position'])

            # Datetimeì„ ISO í˜•ì‹ ë¬¸ìžì—´ë¡œ ë³€í™˜
            split_data['created_at'] = split_data['created_at'].isoformat()
            split_data['updated_at'] = split_data['updated_at'].isoformat()

        print(f"[DEBUG][DB Async][get_split_elements_for_project] Found {len(split_elements_list)} active split elements")
        print(f"[DEBUG][DB Async][get_split_elements_for_project] {len(raw_element_ids_with_splits)} RawElements have splits")

        return split_elements_list, raw_element_ids_with_splits

    except Exception as e:
        print(f"[ERROR][DB Async][get_split_elements_for_project] Exception: {e}")
        import traceback
        traceback.print_exc()
        return [], set()

class RevitConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.all_incoming_uids = set()
        self.project_id_for_fetch = None
        path = self.scope['path']
        if 'revit-connector' in path:
            self.group_name = 'revit_broadcast_group'
            print(f"âœ… [{self.__class__.__name__}] Revit í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ë””ë²„ê¹… ì¶”ê°€
        elif 'blender-connector' in path:
            self.group_name = 'blender_broadcast_group'
            print(f"âœ… [{self.__class__.__name__}] Blender í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ë””ë²„ê¹… ì¶”ê°€
        else:
            self.group_name = None
            print(f"âš ï¸ [{self.__class__.__name__}] ì•Œ ìˆ˜ ì—†ëŠ” ê²½ë¡œë¡œ í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹œë„: {path}") # ë””ë²„ê¹… ì¶”ê°€

        if self.group_name:
            # print(f"âœ… [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.") # ìœ„ì—ì„œ ì´ë¯¸ ì¶œë ¥
            await self.channel_layer.group_add(self.group_name, self.channel_name)
        await self.accept()

    async def disconnect(self, close_code):
        if hasattr(self, 'group_name') and self.group_name:
            print(f"âŒ [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ê°€ '{self.group_name}' ê·¸ë£¹ì—ì„œ ë‚˜ê°‘ë‹ˆë‹¤ (Code: {close_code}).") # ë””ë²„ê¹… ì¶”ê°€
            await self.channel_layer.group_discard(self.group_name, self.channel_name)

    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"\nâœ‰ï¸  [{self.__class__.__name__}] í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'") # ê¸°ì¡´ print ìœ ì§€

        if msg_type == 'revit_selection_response':
            # ë””ë²„ê¹…: ì„ íƒ ì‘ë‹µ ì „ë‹¬
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ìˆ˜ì‹ í•œ ì„ íƒ ì •ë³´({len(payload)}ê°œ ID)ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {'type': 'broadcast_selection', 'unique_ids': payload}
            )
        elif msg_type == 'fetch_progress_start':
            print("[DEBUG] 'fetch_progress_start' ìˆ˜ì‹ . ë™ê¸°í™” ì„¸ì…˜ì„ ì‹œìž‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            self.all_incoming_uids.clear()

            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì—ì„œ project_idë¥¼ ê°€ì ¸ì˜¤ëŠ” ëŒ€ì‹ , ì´ë¯¸ ì €ìž¥ëœ ê°’ì„ í™•ì¸í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            print(f"  - í˜„ìž¬ ì„¸ì…˜ì˜ í”„ë¡œì íŠ¸ ID: {self.project_id_for_fetch}") # ê¸°ì¡´ print ìœ ì§€
            if not self.project_id_for_fetch:
                print("[CRITICAL ERROR] 'fetch_progress_start' ì‹œì ì— í”„ë¡œì íŠ¸ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ë™ê¸°í™”ê°€ ì‹¤íŒ¨í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ìž…ë‹ˆë‹¤. â–²â–²â–²

            print(f"  - ì „ì²´ ê°ì²´ ìˆ˜: {payload.get('total_elements')}") # ê¸°ì¡´ print ìœ ì§€
            # ë””ë²„ê¹…: ì§„í–‰ ì‹œìž‘ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì‹œìž‘ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        elif msg_type == 'fetch_progress_update':
            print(f"[DEBUG] 'fetch_progress_update' ìˆ˜ì‹ . ì²˜ë¦¬ëœ ê°ì²´: {payload.get('processed_count')}") # ê¸°ì¡´ print ìœ ì§€

            # â–¼â–¼â–¼ [ìˆ˜ì •] payloadì˜ project_id ëŒ€ì‹  selfì— ì €ìž¥ëœ project_idë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. â–¼â–¼â–¼
            project_id = self.project_id_for_fetch
            # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ìž…ë‹ˆë‹¤. â–²â–²â–²

            elements_data = [json.loads(s) for s in payload.get('elements', [])]

            chunk_uids = {item['UniqueId'] for item in elements_data if item and 'UniqueId' in item}
            self.all_incoming_uids.update(chunk_uids)
            print(f"  - ì´ë²ˆ ì²­í¬ì˜ UniqueId {len(chunk_uids)}ê°œ ì¶”ê°€. í˜„ìž¬ê¹Œì§€ ì´ {len(self.all_incoming_uids)}ê°œ ìˆ˜ì‹ .") # ê¸°ì¡´ print ìœ ì§€

            # ë””ë²„ê¹…: ì§„í–‰ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
            if project_id and elements_data:
                # ë””ë²„ê¹…: DB ë™ê¸°í™” ì‹œìž‘
                print(f"  ðŸ”„ [{self.__class__.__name__}] ìˆ˜ì‹ í•œ {len(elements_data)}ê°œ ê°ì²´ì— ëŒ€í•œ DB ë™ê¸°í™”ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤ (Project: {project_id}).")
                await asyncio.shield(self.sync_chunk_of_elements(project_id, elements_data))

        elif msg_type == 'fetch_progress_complete':
            print("[DEBUG] 'fetch_progress_complete' ìˆ˜ì‹ . ë™ê¸°í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ê³  ì‚­ì œ ìž‘ì—…ì„ ì‹œìž‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
            if self.project_id_for_fetch:
                # ë””ë²„ê¹…: ì‚­ì œ ìž‘ì—… ì‹œìž‘
                print(f"  ðŸ—‘ï¸ [{self.__class__.__name__}] ì˜¤ëž˜ëœ ê°ì²´ ì‚­ì œ ìž‘ì—…ì„ ì‹œìž‘í•©ë‹ˆë‹¤ (Project: {self.project_id_for_fetch}).")
                await cleanup_old_elements(self.project_id_for_fetch, self.all_incoming_uids)
            else:
                print("[WARNING] 'project_id_for_fetch'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì‚­ì œ ìž‘ì—…ì„ ê±´ë„ˆëœë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

            # ë””ë²„ê¹…: ì™„ë£Œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì™„ë£Œ ì •ë³´ë¥¼ í”„ë¡ íŠ¸ì—”ë“œë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(
                FrontendConsumer.frontend_group_name,
                {"type": "broadcast_progress", "data": data}
            )
        else:
            print(f"[WARNING] ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ ìœ í˜•ìž…ë‹ˆë‹¤: {msg_type}") # ê¸°ì¡´ print ìœ ì§€

    async def send_command(self, event):
        command_data = event['command_data']

        # â–¼â–¼â–¼ [ì¶”ê°€] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ëª…ë ¹ì¼ ê²½ìš°, project_idë¥¼ ë¯¸ë¦¬ ì €ìž¥í•©ë‹ˆë‹¤. â–¼â–¼â–¼
        if command_data.get('command') == 'fetch_all_elements_chunked':
            project_id = command_data.get('project_id')
            self.project_id_for_fetch = project_id
            print(f"ðŸš€ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì„¸ì…˜ ì‹œìž‘. Project ID '{project_id}'ë¥¼ ì €ìž¥í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ ìž…ë‹ˆë‹¤. â–²â–²â–²

        print(f"âž¡ï¸  [{self.__class__.__name__}] '{self.group_name}' ê·¸ë£¹ì˜ í´ë¼ì´ì–¸íŠ¸ë¡œ ëª…ë ¹ì„ ë³´ëƒ…ë‹ˆë‹¤: {command_data.get('command')}") # ê¸°ì¡´ print ìœ ì§€
        try: # ë””ë²„ê¹…: send ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì¶”ê°€
            await self.send(text_data=json.dumps(command_data))
        except Exception as e:
            print(f"[ERROR][{self.__class__.__name__}] Failed to send command to client: {e}")


    @database_sync_to_async
    def sync_chunk_of_elements(self, project_id, parsed_data):
        print(f"  [DB Sync] ì²­í¬ ë™ê¸°í™” ì‹œìž‘: {len(parsed_data)}ê°œ ê°ì²´") # ê¸°ì¡´ print ìœ ì§€
        try:
            project = Project.objects.get(id=project_id)
            uids_in_chunk = [item['UniqueId'] for item in parsed_data if item and 'UniqueId' in item]
            existing_elements_map = {el.element_unique_id: el for el in project.raw_elements.filter(element_unique_id__in=uids_in_chunk)}
            print(f"    - DBì—ì„œ ê¸°ì¡´ ê°ì²´ {len(existing_elements_map)}ê°œ ì°¾ìŒ.") # ë””ë²„ê¹… ì¶”ê°€

            to_update, to_create = [], []
            for item in parsed_data:
                if not item or 'UniqueId' not in item: continue
                uid = item['UniqueId']

                # â–¼â–¼â–¼ [ìˆ˜ì •] ë™ì  í‰íƒ„í™” ì²˜ë¦¬ (BIM ë„êµ¬ì— êµ¬ì• ë°›ì§€ ì•ŠìŒ) â–¼â–¼â–¼
                flattened_data = flatten_bim_data(item)

                # ê³ ì • í•„ë“œë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ ì¤‘ì²© ê°ì²´ëŠ” ì œê±° (ì´ë¯¸ í‰íƒ„í™”ë¨)
                # FIXED_FIELDS = {'Name', 'IfcClass', 'ElementId', 'UniqueId', 'System'}
                FIXED_FIELDS = {'Name', 'IfcClass', 'ElementId', 'UniqueId', 'System'}

                # ê³ ì • í•„ë“œì™€ í‰íƒ„í™”ëœ ë°ì´í„°ë§Œ ìœ ì§€
                processed_item = {k: v for k, v in item.items() if k in FIXED_FIELDS}
                processed_item.update(flattened_data)
                # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

                # â–¼â–¼â–¼ [ì¶”ê°€] 3D ë·°ì–´ í˜¸í™˜ì„±: System.Geometryë¥¼ Parameters.Geometryë¡œë„ ë³µì‚¬ â–¼â–¼â–¼
                if 'System' in processed_item and isinstance(processed_item['System'], dict):
                    if 'Geometry' in processed_item['System']:
                        # Parameters í•„ë“œê°€ ì—†ìœ¼ë©´ ìƒì„±
                        if 'Parameters' not in processed_item:
                            processed_item['Parameters'] = {}
                        # System.Geometryë¥¼ Parameters.Geometryë¡œ ë³µì‚¬ (3D ë·°ì–´ìš©)
                        processed_item['Parameters']['Geometry'] = processed_item['System']['Geometry']
                # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²
                # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

                if uid in existing_elements_map:
                    elem = existing_elements_map[uid]
                    # [ê°œì„ ] raw_dataê°€ ì‹¤ì œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸ í›„ ì—…ë°ì´íŠ¸ ëª©ë¡ì— ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
                    if elem.raw_data != processed_item:
                        elem.raw_data = processed_item
                        to_update.append(elem)
                else:
                    to_create.append(RawElement(project=project, element_unique_id=uid, raw_data=processed_item))

            if to_update:
                updated_ids = [el.id for el in to_update] # ë””ë²„ê¹…ìš©
                RawElement.objects.bulk_update(to_update, ['raw_data'])
                print(f"    - {len(to_update)}ê°œ ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ. (IDs: {updated_ids[:5]}...)") # ê¸°ì¡´ print ìœ ì§€ (ID ì¶”ê°€)

                # Geometry volume ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                updated_with_volume = []
                for elem in to_update:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        updated_with_volume.append(elem)
                if updated_with_volume:
                    RawElement.objects.bulk_update(updated_with_volume, ['geometry_volume'])
                    print(f"    - {len(updated_with_volume)}ê°œ ê°ì²´ì˜ Geometry volume ê³„ì‚° ì™„ë£Œ.")

            if to_create:
                created_objs = RawElement.objects.bulk_create(to_create, ignore_conflicts=True)
                print(f"    - {len(created_objs)}ê°œ ê°ì²´ ìƒˆë¡œ ìƒì„± ì™„ë£Œ.") # ê¸°ì¡´ print ìœ ì§€ (ì‹¤ì œ ìƒì„±ëœ ìˆ˜ ì‚¬ìš©)

                # Geometry volume ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                created_with_volume = []
                for elem in created_objs:
                    volume = elem.calculate_geometry_volume()
                    if volume is not None:
                        elem.geometry_volume = volume
                        created_with_volume.append(elem)
                if created_with_volume:
                    RawElement.objects.bulk_update(created_with_volume, ['geometry_volume'])
                    print(f"    - {len(created_with_volume)}ê°œ ê°ì²´ì˜ Geometry volume ê³„ì‚° ì™„ë£Œ.")

        except Exception as e:
            print(f"[ERROR] sync_chunk_of_elements DB ìž‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ê¸°ì¡´ print ìœ ì§€

@database_sync_to_async
def cleanup_old_elements(project_id, incoming_uids):
    print(f"  [DB Cleanup] ì‚­ì œ ìž‘ì—… ì‹œìž‘ (Project ID: {project_id})") # ê¸°ì¡´ print ìœ ì§€
    try:
        project = Project.objects.get(id=project_id)

        # [ê°œì„ ] QuerySet ì‚¬ìš© ìµœì í™” (values_list ëŒ€ì‹  set ì§ì ‘ ì‚¬ìš©)
        db_uids = set(project.raw_elements.values_list('element_unique_id', flat=True))
        print(f"    - í˜„ìž¬ DBì— ì¡´ìž¬í•˜ëŠ” UniqueId ìˆ˜: {len(db_uids)}") # ê¸°ì¡´ print ìœ ì§€

        incoming_uids_set = set(incoming_uids)
        print(f"    - ì´ë²ˆ ë™ê¸°í™”ì—ì„œ ë°›ì€ UniqueId ìˆ˜: {len(incoming_uids_set)}") # ê¸°ì¡´ print ìœ ì§€

        to_delete_uids = db_uids - incoming_uids_set
        print(f"    - ì‚­ì œ ëŒ€ìƒ UniqueId ìˆ˜: {len(to_delete_uids)}") # ê¸°ì¡´ print ìœ ì§€

        if to_delete_uids:
            print(f"    - ì‚­ì œ ëŒ€ìƒ ID (ìµœëŒ€ 10ê°œ í‘œì‹œ): {list(to_delete_uids)[:10]}") # ê¸°ì¡´ print ìœ ì§€

            # â–¼â–¼â–¼ [ì¶”ê°€] RawElementë¥¼ ì‚­ì œí•˜ê¸° ì „ì—, ì—°ê´€ëœ ë°ì´í„° í™•ì¸ ë° ì •ë¦¬ â–¼â–¼â–¼

            # 1. ì—°ê´€ëœ SplitElement í™•ì¸ (CASCADEë¡œ ìžë™ ì‚­ì œë¨)
            split_elements_count = SplitElement.objects.filter(
                project=project,
                raw_element__element_unique_id__in=to_delete_uids
            ).count()
            print(f"    - [SplitElement Cleanup] {split_elements_count}ê°œì˜ ë¶„í•  ê°ì²´ê°€ CASCADEë¡œ ìžë™ ì‚­ì œë  ì˜ˆì •ìž…ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

            # 2. ì—°ê´€ëœ QuantityMember í™•ì¸ ë° ì‚­ì œ (SET_NULLì´ë¯€ë¡œ ëª…ì‹œì  ì‚­ì œ)
            print(f"    - [QuantityMember Cleanup] ì‚­ì œë  RawElementì™€ ì—°ê´€ëœ ìˆ˜ëŸ‰ì‚°ì¶œë¶€ìž¬ë¥¼ ë¨¼ì € ì‚­ì œí•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

            # raw_element í•„ë“œê°€ nullì´ ì•„ë‹Œ(ì¦‰, BIM ê°ì²´ì™€ ì—°ê³„ëœ) ìˆ˜ëŸ‰ì‚°ì¶œë¶€ìž¬ ì¤‘ì—ì„œ
            # ì‚­ì œë  RawElementì˜ unique_idë¥¼ ê°€ì§„ ë¶€ìž¬ë“¤ì„ ì°¾ì•„ ì‚­ì œí•©ë‹ˆë‹¤.
            deletable_members = QuantityMember.objects.filter(
                project=project,
                raw_element__element_unique_id__in=to_delete_uids
            )

            member_deleted_count, deleted_details = deletable_members.delete() # ìƒì„¸ ì •ë³´ ë°›ì„ ìˆ˜ ìžˆìŒ
            print(f"    - [QuantityMember Cleanup] {member_deleted_count}ê°œì˜ ì—°ê´€ëœ ìˆ˜ëŸ‰ì‚°ì¶œë¶€ìž¬ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. Details: {deleted_details}") # ê¸°ì¡´ print ìœ ì§€ (ìƒì„¸ ì •ë³´ ì¶”ê°€)
            # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ ìž…ë‹ˆë‹¤. â–²â–²â–²

            deleted_count, deleted_raw_details = project.raw_elements.filter(element_unique_id__in=to_delete_uids).delete()
            print(f"    - DBì—ì„œ {deleted_count}ê°œì˜ ì˜¤ëž˜ëœ RawElement ê°ì²´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œí–ˆìŠµë‹ˆë‹¤. Details: {deleted_raw_details}") # ê¸°ì¡´ print ìœ ì§€ (ìƒì„¸ ì •ë³´ ì¶”ê°€)
            print(f"    - âœ… CASCADE íš¨ê³¼ë¡œ ì¸í•´ ê´€ë ¨ëœ SplitElement, QuantityMember(ë¶„í• ), CostItem(ë¶„í• )ë„ í•¨ê»˜ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("    - ì‚­ì œí•  ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ê°€ ìµœì‹  ìƒíƒœìž…ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

    except Exception as e:
        print(f"[ERROR] cleanup_old_elements DB ìž‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ê¸°ì¡´ print ìœ ì§€

class FrontendConsumer(AsyncWebsocketConsumer):
    frontend_group_name = 'frontend_group'
    async def connect(self):
        # ë””ë²„ê¹…: í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²°
        print(f"âœ… [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ê°€ '{self.frontend_group_name}' ê·¸ë£¹ì— ì°¸ì—¬í•©ë‹ˆë‹¤.")
        await self.channel_layer.group_add(self.frontend_group_name, self.channel_name); await self.accept()
    async def disconnect(self, close_code):
        # ë””ë²„ê¹…: í”„ë¡ íŠ¸ì—”ë“œ ì—°ê²° í•´ì œ
        print(f"âŒ [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì € í´ë¼ì´ì–¸íŠ¸ê°€ '{self.frontend_group_name}' ê·¸ë£¹ì—ì„œ ë‚˜ê°‘ë‹ˆë‹¤ (Code: {close_code}).")
        await self.channel_layer.group_discard(self.frontend_group_name, self.channel_name)


    async def receive(self, text_data):
        data = json.loads(text_data)
        msg_type = data.get('type')
        payload = data.get('payload', {})
        print(f"âœ‰ï¸ [{self.__class__.__name__}] ì›¹ ë¸Œë¼ìš°ì €ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹ : type='{msg_type}'") # ê¸°ì¡´ print ìœ ì§€

        if msg_type == 'command_to_client':
            target_group = payload.pop('target_group', 'revit_broadcast_group')
            print(f"   âž¡ï¸  '{target_group}' ê·¸ë£¹ìœ¼ë¡œ ëª…ë ¹ì„ ì „ë‹¬í•©ë‹ˆë‹¤: {payload}") # ê¸°ì¡´ print ìœ ì§€
            await self.channel_layer.group_send(target_group, {'type': 'send.command', 'command_data': payload})

        # â–¼â–¼â–¼ [ìˆ˜ì •] get_all_elements ë©”ì‹œì§€ ì²˜ë¦¬ ë¶€ë¶„ì— printë¬¸ ì¶”ê°€ â–¼â–¼â–¼
        elif msg_type == 'get_all_elements':
            project_id = payload.get('project_id')
            if project_id:
                print(f"\n[DEBUG] í”„ë¡ íŠ¸ì—”ë“œë¡œë¶€í„° '{project_id}' í”„ë¡œì íŠ¸ì˜ ëª¨ë“  ê°ì²´ ë°ì´í„° ìš”ì²­ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€
                total_elements = await get_total_element_count(project_id)
                print(f"[DEBUG] ì´ {total_elements}ê°œì˜ ê°ì²´ë¥¼ ì „ì†¡ ì‹œìž‘í•©ë‹ˆë‹¤.") # ê¸°ì¡´ print ìœ ì§€

                # â–¼â–¼â–¼ [ì¶”ê°€] ë¶„í•  ê°ì²´ ë°ì´í„° ì¡°íšŒ â–¼â–¼â–¼
                split_elements, raw_element_ids_with_splits = await get_split_elements_for_project(project_id)
                print(f"[DEBUG] {len(split_elements)}ê°œì˜ í™œì„± ë¶„í•  ê°ì²´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                print(f"[DEBUG] {len(raw_element_ids_with_splits)}ê°œì˜ BIM ì›ë³¸ ê°ì²´ê°€ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

                await self.send(text_data=json.dumps({
                    'type': 'revit_data_start',
                    'payload': {
                        'total': total_elements,
                        'split_elements': split_elements,  # â–¼â–¼â–¼ [ì¶”ê°€] ë¶„í•  ê°ì²´ ë°ì´í„° ì „ì†¡ â–¼â–¼â–¼
                        'raw_element_ids_with_splits': list(raw_element_ids_with_splits)  # â–¼â–¼â–¼ [ì¶”ê°€] ë¶„í• ëœ BIM ì›ë³¸ ID ëª©ë¡ â–¼â–¼â–¼
                    }
                }))

                CHUNK_SIZE = 1000 # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í›„ ì¡°ì ˆ ê°€ëŠ¥
                sent_count = 0
                for offset in range(0, total_elements, CHUNK_SIZE):
                    chunk = await get_serialized_element_chunk(project_id, offset, CHUNK_SIZE)
                    if chunk:
                        await self.send(text_data=json.dumps({'type': 'revit_data_chunk', 'payload': chunk}))
                        sent_count += len(chunk)
                        # ë””ë²„ê¹…: ì²­í¬ ì „ì†¡ ë¡œê·¸ (ë„ˆë¬´ ë¹ˆë²ˆí•  ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì¡°ê±´ë¶€ ì¶œë ¥ ê³ ë ¤)
                        # print(f"    [WebSocket Send] Sent chunk: {offset+1}-{sent_count}/{total_elements}")
                    await asyncio.sleep(0.01) # ë¶€í•˜ ë¶„ì‚°ì„ ìœ„í•œ ì•½ê°„ì˜ ì§€ì—°

                print(f"[DEBUG] {sent_count}ê°œ ê°ì²´ ì „ì†¡ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤ (ì´ {total_elements}ê°œ ëŒ€ìƒ).") # ê¸°ì¡´ print ìœ ì§€ (ì‹¤ì œ ì „ì†¡ëœ ìˆ˜ í¬í•¨)
                await self.send(text_data=json.dumps({'type': 'revit_data_complete'}))
        # â–²â–²â–² [ìˆ˜ì •] ì—¬ê¸°ê¹Œì§€ ìž…ë‹ˆë‹¤. â–²â–²â–²

        elif msg_type == 'get_tags':
            project_id = payload.get('project_id')
            if project_id:
                # ë””ë²„ê¹…: íƒœê·¸ ìš”ì²­
                print(f"[DEBUG] '{project_id}' í”„ë¡œì íŠ¸ì˜ íƒœê·¸ ëª©ë¡ ìš”ì²­ ìˆ˜ì‹ .")
                tags = await self.db_get_tags(project_id)
                await self.send_tags_update(tags)
        
        elif msg_type in ['create_tag', 'update_tag']:
            project_id = payload.get('project_id')
            if not project_id: return
            if msg_type == 'create_tag':
                # ë””ë²„ê¹…: íƒœê·¸ ìƒì„± ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ìƒì„± ìš”ì²­: name='{payload.get('name')}'")
                await self.db_create_tag(project_id, payload.get('name'))
            elif msg_type == 'update_tag':
                # ë””ë²„ê¹…: íƒœê·¸ ìˆ˜ì • ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ìˆ˜ì • ìš”ì²­: id='{payload.get('tag_id')}', new_name='{payload.get('new_name')}'")
                await self.db_update_tag(payload.get('tag_id'), payload.get('new_name'))

            # ìƒì„± ë˜ëŠ” ìˆ˜ì • í›„ì—ëŠ” íƒœê·¸ ëª©ë¡ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            # ë””ë²„ê¹…: íƒœê·¸ ëª©ë¡ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ íƒœê·¸ ëª©ë¡ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

        elif msg_type == 'delete_tag':
            project_id = payload.get('project_id')
            tag_id = payload.get('tag_id')
            if not all([project_id, tag_id]): return
            # ë””ë²„ê¹…: íƒœê·¸ ì‚­ì œ ìš”ì²­
            print(f"[DEBUG] íƒœê·¸ ì‚­ì œ ìš”ì²­: id='{tag_id}'")

            # 1. íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , ì˜í–¥ì„ ë°›ì•˜ë˜ elementë“¤ì˜ ID ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
            affected_ids = await self.db_delete_tag(tag_id)
            # ë””ë²„ê¹…: ì‚­ì œ ê²°ê³¼ ë° ì˜í–¥ ë°›ì€ ê°ì²´ ID
            print(f"  - íƒœê·¸ ì‚­ì œ ì™„ë£Œ. ì˜í–¥ ë°›ì€ ê°ì²´ ìˆ˜: {len(affected_ids)}")

            # 2. ë³€ê²½ëœ ì „ì²´ íƒœê·¸ ëª©ë¡ì„ ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            tags = await self.db_get_tags(project_id)
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ íƒœê·¸ ëª©ë¡ì„ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_tags', 'tags': tags})

            # 3. ë§Œì•½ ì˜í–¥ì„ ë°›ì€ elementê°€ ìžˆì—ˆë‹¤ë©´, í•´ë‹¹ elementë“¤ì˜ ìµœì‹  ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.
            if affected_ids:
                elements = await serialize_specific_elements(affected_ids)
                print(f"  âž¡ï¸ [{self.__class__.__name__}] ì˜í–¥ ë°›ì€ {len(elements)}ê°œ ê°ì²´ì˜ ì—…ë°ì´íŠ¸ ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
                await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        elif msg_type in ['assign_tags', 'clear_tags']:
            element_ids = payload.get('element_ids')
            if msg_type == 'assign_tags':
                # ë””ë²„ê¹…: íƒœê·¸ í• ë‹¹ ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ í• ë‹¹ ìš”ì²­: tag_id='{payload.get('tag_id')}', elements={len(element_ids)}ê°œ")
                await self.db_assign_tags(payload.get('tag_id'), element_ids)
            elif msg_type == 'clear_tags':
                # ë””ë²„ê¹…: íƒœê·¸ ì œê±° ìš”ì²­
                print(f"[DEBUG] íƒœê·¸ ì œê±° ìš”ì²­: elements={len(element_ids)}ê°œ")
                await self.db_clear_tags(element_ids)
            elements = await serialize_specific_elements(element_ids)
            # ë””ë²„ê¹…: ê°ì²´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            print(f"  âž¡ï¸ [{self.__class__.__name__}] ì—…ë°ì´íŠ¸ëœ {len(elements)}ê°œ ê°ì²´ ì •ë³´ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
            await self.channel_layer.group_send(self.frontend_group_name, {'type': 'broadcast_elements', 'elements': elements})
        # â–¼â–¼â–¼ [ì¶”ê°€] AI í•™ìŠµ ìƒíƒœ í´ë§ ìš”ì²­ ì²˜ë¦¬ â–¼â–¼â–¼
        elif msg_type == 'get_training_status':
             task_id = payload.get('task_id')
             if task_id and task_id in training_progress:
                 print(f"[DEBUG] AI í•™ìŠµ ìƒíƒœ ìš”ì²­ ìˆ˜ì‹  (Task ID: {task_id}). í˜„ìž¬ ìƒíƒœ ì „ì†¡.")
                 await self.send(text_data=json.dumps({
                     'type': 'training_progress_update',
                     'project_id': payload.get('project_id'), # ì›ë³¸ ìš”ì²­ì˜ project_id ì „ë‹¬
                     'task_id': task_id,
                     'progress': training_progress[task_id]
                 }))
             else:
                 print(f"[WARN] ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì™„ë£Œëœ Task ID({task_id})ì— ëŒ€í•œ ìƒíƒœ ìš”ì²­ ìˆ˜ì‹ .")
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

        # â–¼â–¼â–¼ [ì¶”ê°€] 3D ê°ì²´ ë¶„í•  ì €ìž¥ ì²˜ë¦¬ â–¼â–¼â–¼
        elif msg_type == 'save_split':
            print(f"[DEBUG] 3D ê°ì²´ ë¶„í•  ì €ìž¥ ìš”ì²­ ìˆ˜ì‹ ")
            try:
                result = await self.db_save_split_element(payload)
                split_id = result['split_id']
                print(f"[DEBUG] ë¶„í•  ê°ì²´ ì €ìž¥ ì„±ê³µ: {split_id}")
                print(f"[DEBUG] ìƒì„±ëœ QuantityMembers: {result['created_qm_count']}, CostItems: {result['created_ci_count']}")
                await self.send(text_data=json.dumps({
                    'type': 'split_saved',
                    'split_id': str(split_id),
                    'raw_element_id': str(payload.get('raw_element_id')),
                    'split_part_type': payload.get('split_part_type'),
                    'created_qm_count': result['created_qm_count'],
                    'created_ci_count': result['created_ci_count'],
                    'success': True
                }))
            except Exception as e:
                print(f"[ERROR] ë¶„í•  ê°ì²´ ì €ìž¥ ì‹¤íŒ¨: {str(e)}")
                import traceback
                traceback.print_exc()
                await self.send(text_data=json.dumps({
                    'type': 'split_save_error',
                    'error': str(e),
                    'success': False
                }))
        # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

        else:
            # ë””ë²„ê¹…: ì•Œ ìˆ˜ ì—†ëŠ” ë©”ì‹œì§€ íƒ€ìž…
            print(f"[WARNING][{self.__class__.__name__}] ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ ìœ í˜•: {msg_type}")


    async def broadcast_progress(self, event):
        # ë””ë²„ê¹…: ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  âž¡ï¸ [{self.__class__.__name__}] ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸: type='{event['data'].get('type')}'")
        await self.send(text_data=json.dumps(event['data']))
    async def broadcast_tags(self, event):
        # ë””ë²„ê¹…: íƒœê·¸ ëª©ë¡ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  âž¡ï¸ [{self.__class__.__name__}] íƒœê·¸ ëª©ë¡ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['tags'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': event['tags']}))
    async def broadcast_elements(self, event):
        # ë””ë²„ê¹…: ê°ì²´ ì •ë³´ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  âž¡ï¸ [{self.__class__.__name__}] ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['elements'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'elements_updated', 'elements': event['elements']}))
    async def broadcast_selection(self, event):
        # ë””ë²„ê¹…: ì„ íƒ ì •ë³´ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        print(f"  âž¡ï¸ [{self.__class__.__name__}] Revit/Blender ì„ íƒ ì •ë³´ ì—…ë°ì´íŠ¸ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ({len(event['unique_ids'])}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'revit_selection_update', 'unique_ids': event['unique_ids']}))

    # â–¼â–¼â–¼ [ì¶”ê°€] AI í•™ìŠµ ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸ í•¸ë“¤ëŸ¬ â–¼â–¼â–¼
    async def broadcast_training_progress(self, event):
        """views.pyì—ì„œ í˜¸ì¶œë˜ì–´ AI í•™ìŠµ ì§„í–‰ë¥ ì„ íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ ê·¸ë£¹ì—ê²Œ ì „ì†¡"""
        print(f"  âž¡ï¸ [{self.__class__.__name__}] AI í•™ìŠµ ì§„í–‰ë¥  ë¸Œë¡œë“œìºìŠ¤íŠ¸ (Task ID: {event['task_id']}, Status: {event['progress']['status']}).")
        await self.send(text_data=json.dumps({
            'type': 'training_progress_update', # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì„ ë©”ì‹œì§€ íƒ€ìž…
            'project_id': event['project_id'],
            'task_id': event['task_id'],
            'progress': event['progress'],
        }))
    # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

    async def send_tags_update(self, tags):
        # ë””ë²„ê¹…: íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ì—ê²Œ íƒœê·¸ ëª©ë¡ ì „ì†¡
        print(f"  âž¡ï¸ [{self.__class__.__name__}] í˜„ìž¬ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ íƒœê·¸ ëª©ë¡ ì „ì†¡ ({len(tags)}ê°œ).")
        await self.send(text_data=json.dumps({'type': 'tags_updated', 'tags': tags}))

    @database_sync_to_async
    def db_get_tags(self, project_id):
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì¡°íšŒ
        print(f"[DEBUG][DB Async][db_get_tags] Querying tags for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tags = list(project.classification_tags.all())
        print(f"[DEBUG][DB Async][db_get_tags] Found {len(tags)} tags.")
        return serialize_tags(tags)
    @database_sync_to_async
    def db_create_tag(self, project_id, name):
        if not name: return
        # ë””ë²„ê¹…: DBì— íƒœê·¸ ìƒì„±
        print(f"[DEBUG][DB Async][db_create_tag] Creating tag '{name}' for project: {project_id}")
        project = Project.objects.get(id=project_id)
        tag, created = QuantityClassificationTag.objects.get_or_create(project=project, name=name)
        print(f"[DEBUG][DB Async][db_create_tag] Tag '{name}' {'created' if created else 'already exists'}.")
    @database_sync_to_async
    def db_update_tag(self, tag_id, new_name):
        if not new_name: return
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ìˆ˜ì •
        print(f"[DEBUG][DB Async][db_update_tag] Updating tag ID '{tag_id}' to name '{new_name}'")
        try:
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            tag.name = new_name; tag.save()
            print(f"[DEBUG][DB Async][db_update_tag] Tag ID '{tag_id}' updated successfully.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_update_tag] Tag ID '{tag_id}' not found.")
    @database_sync_to_async
    def db_delete_tag(self, tag_id):
        """
        íƒœê·¸ë¥¼ ì‚­ì œí•˜ê³ , í•´ë‹¹ íƒœê·¸ì— ì˜í–¥ì„ ë°›ì•˜ë˜ RawElementì˜ ID ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì‚­ì œ
        print(f"[DEBUG][DB Async][db_delete_tag] Deleting tag ID '{tag_id}'")
        try:
            # ì‚­ì œí•˜ê¸° ì „ì—, ì–´ë–¤ ê°ì²´ë“¤ì´ ì´ íƒœê·¸ë¥¼ ê°€ì§€ê³  ìžˆì—ˆëŠ”ì§€ IDë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            tag_to_delete = QuantityClassificationTag.objects.prefetch_related('raw_elements').get(id=tag_id)
            affected_element_ids = list(tag_to_delete.raw_elements.values_list('id', flat=True))
            print(f"[DEBUG][DB Async][db_delete_tag] Found {len(affected_element_ids)} affected elements before deletion.")

            # íƒœê·¸ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. (ManyToManyField ê´€ê³„ëŠ” ìžë™ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤)
            tag_to_delete.delete()
            print(f"[DEBUG][DB Async][db_delete_tag] Tag ID '{tag_id}' deleted successfully.")

            return affected_element_ids
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_delete_tag] Tag ID '{tag_id}' not found.")
            return [] # ì‚­ì œí•  íƒœê·¸ê°€ ì—†ìœ¼ë©´ ë¹ˆ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        except Exception as e:
            print(f"[ERROR][DB Async][db_delete_tag] Exception during deletion: {e}")
            return []
    @database_sync_to_async
    def db_assign_tags(self, tag_id, element_ids):
        """
        ìˆ˜ë™ìœ¼ë¡œ íƒœê·¸ë¥¼ í• ë‹¹í•©ë‹ˆë‹¤ (assignment_type='manual')
        """
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ í• ë‹¹
        print(f"[DEBUG][DB Async][db_assign_tags] Manually assigning tag ID '{tag_id}' to {len(element_ids)} elements.")
        try:
            from connections.models import ElementClassificationAssignment
            tag = QuantityClassificationTag.objects.get(id=tag_id)
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            added_count = 0
            for element in elements_to_update:
                _, created = ElementClassificationAssignment.objects.get_or_create(
                    raw_element=element,
                    classification_tag=tag,
                    defaults={
                        'assignment_type': 'manual',
                        'assigned_by_rule': None
                    }
                )
                if created:
                    added_count += 1
            print(f"[DEBUG][DB Async][db_assign_tags] Tag assignment complete. {added_count} new manual assignments.")
        except QuantityClassificationTag.DoesNotExist:
            print(f"[ERROR][DB Async][db_assign_tags] Tag ID '{tag_id}' not found.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_assign_tags] Exception during assignment: {e}")
    @database_sync_to_async
    def db_clear_tags(self, element_ids):
        # ë””ë²„ê¹…: DBì—ì„œ íƒœê·¸ ì œê±°
        print(f"[DEBUG][DB Async][db_clear_tags] Clearing tags from {len(element_ids)} elements.")
        try:
            elements_to_update = RawElement.objects.filter(id__in=element_ids)
            cleared_count = 0
            for element in elements_to_update:
                if element.classification_tags.exists():
                    element.classification_tags.clear()
                    cleared_count += 1
            print(f"[DEBUG][DB Async][db_clear_tags] Tag clearing complete. {cleared_count} elements had tags cleared.")
        except Exception as e:
            print(f"[ERROR][DB Async][db_clear_tags] Exception during clearing: {e}")

    # â–¼â–¼â–¼ [ì¶”ê°€] 3D ê°ì²´ ë¶„í•  ì €ìž¥ ë©”ì„œë“œ â–¼â–¼â–¼
    @database_sync_to_async
    def db_save_split_element(self, payload):
        """
        3D ë·°ì–´ì—ì„œ ìƒì„±ëœ ë¶„í•  ê°ì²´ë¥¼ DBì— ì €ìž¥

        payload êµ¬ì¡°:
        {
            'project_id': UUID,
            'raw_element_id': UUID,
            'parent_split_id': UUID (optional),
            'original_geometry_volume': Decimal,
            'geometry_volume': Decimal,
            'volume_ratio': Decimal,
            'split_method': 'plane' | 'sketch',
            'split_axis': 'x' | 'y' | 'z' (plane only),
            'split_position': Decimal (plane only),
            'split_part_type': 'bottom' | 'top' | 'remainder' | 'extracted',
            'geometry_data': {...},
            'sketch_data': {...} (sketch only)
        }
        """
        print(f"[DEBUG][DB Async][db_save_split_element] Saving split element...")

        try:
            # Projectì™€ RawElement ê°€ì ¸ì˜¤ê¸°
            project = Project.objects.get(id=payload['project_id'])
            raw_element = RawElement.objects.get(id=payload['raw_element_id'])

            # Parent split (optional)
            parent_split = None
            if payload.get('parent_split_id'):
                parent_split = SplitElement.objects.get(id=payload['parent_split_id'])

            # SplitElement ìƒì„±
            split_element = SplitElement.objects.create(
                project=project,
                raw_element=raw_element,
                parent_split=parent_split,
                original_geometry_volume=payload['original_geometry_volume'],
                geometry_volume=payload['geometry_volume'],
                volume_ratio=payload['volume_ratio'],
                split_method=payload['split_method'],
                split_axis=payload.get('split_axis'),  # plane only
                split_position=payload.get('split_position'),  # plane only
                split_part_type=payload['split_part_type'],
                geometry_data=payload.get('geometry_data', {}),
                sketch_data=payload.get('sketch_data', {}),
                is_active=True
            )

            print(f"[DEBUG][DB Async][db_save_split_element] Split element saved successfully:")
            print(f"  - ID: {split_element.id}")
            print(f"  - RawElement: {raw_element.element_unique_id}")
            print(f"  - Method: {split_element.split_method}")
            print(f"  - Part Type: {split_element.split_part_type}")
            print(f"  - Volume: {split_element.geometry_volume}")
            print(f"  - Ratio: {float(split_element.volume_ratio) * 100:.2f}%")

            # â–¼â–¼â–¼ QuantityMemberì™€ CostItem ë³µì œ ë¡œì§ â–¼â–¼â–¼
            # 1. ì›ë³¸ QuantityMembers ì¡°íšŒ (parent_split ë˜ëŠ” raw_elementì—ì„œ)
            # 2. ë¶€ëª¨ ëŒ€ë¹„ volume ratio ê³„ì‚°
            if parent_split:
                # ë¶€ëª¨ ë¶„í•  ê°ì²´ì— ì—°ê²°ëœ QuantityMember ë³µì œ
                # â–¼â–¼â–¼ [ìˆ˜ì •] is_active í•„í„° ì œê±°: ì²« ë²ˆì§¸ splitì—ì„œ ë¹„í™œì„±í™”ë˜ì–´ë„ ë‘ ë²ˆì§¸ splitì—ì„œ ë³µì œ ê°€ëŠ¥ â–¼â–¼â–¼
                source_members = QuantityMember.objects.filter(
                    split_element=parent_split
                )
                # ë¶€ëª¨ ëŒ€ë¹„ volume ratio ê³„ì‚°
                parent_volume = float(parent_split.geometry_volume)
                parent_volume_ratio = float(split_element.geometry_volume) / parent_volume if parent_volume > 0 else 0.5

                # â–¼â–¼â–¼ [ì¶”ê°€] ì•ˆì „ìž¥ì¹˜: volume ratioê°€ 1.0ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° (geometry ê³„ì‚° ì˜¤ë¥˜) â–¼â–¼â–¼
                if parent_volume_ratio > 1.0:
                    print(f"[WARN][DB Async][db_save_split_element] Volume ratio exceeds 1.0! Current: {parent_volume_ratio:.6f}")
                    print(f"[WARN][DB Async][db_save_split_element] This indicates geometry calculation error in frontend")
                    print(f"[WARN][DB Async][db_save_split_element] Clamping to 1.0 to prevent quantity increase")
                    parent_volume_ratio = 1.0
                # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

                print(f"[DEBUG][DB Async][db_save_split_element] Found {source_members.count()} QMs from parent split")
                print(f"[DEBUG][DB Async][db_save_split_element] Parent volume: {parent_volume:.6f}, Current volume: {float(split_element.geometry_volume):.6f}")
                print(f"[DEBUG][DB Async][db_save_split_element] Parent volume ratio (clamped): {parent_volume_ratio:.6f} ({parent_volume_ratio * 100:.2f}%)")
            else:
                # ì›ë³¸ BIM ê°ì²´ì— ì—°ê²°ëœ QuantityMember ë³µì œ
                # â–¼â–¼â–¼ [ìˆ˜ì •] is_active í•„í„° ì œê±°: ì²« ë²ˆì§¸ splitì—ì„œ ë¹„í™œì„±í™”ë˜ì–´ë„ ë‘ ë²ˆì§¸ splitì—ì„œ ë³µì œ ê°€ëŠ¥ â–¼â–¼â–¼
                source_members = QuantityMember.objects.filter(
                    raw_element=raw_element,
                    split_element__isnull=True  # ë¶„í• ë˜ì§€ ì•Šì€ ì›ë³¸ë§Œ
                )
                # ì›ë³¸ BIM ê°ì²´ ëŒ€ë¹„ volume ratioëŠ” split_element.volume_ratio ì‚¬ìš©
                parent_volume_ratio = float(split_element.volume_ratio)

                # â–¼â–¼â–¼ [ì¶”ê°€] ì•ˆì „ìž¥ì¹˜: volume ratioê°€ 1.0ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° â–¼â–¼â–¼
                if parent_volume_ratio > 1.0:
                    print(f"[WARN][DB Async][db_save_split_element] Volume ratio exceeds 1.0! Current: {parent_volume_ratio:.6f}")
                    print(f"[WARN][DB Async][db_save_split_element] Clamping to 1.0 to prevent quantity increase")
                    parent_volume_ratio = 1.0
                # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²

                print(f"[DEBUG][DB Async][db_save_split_element] Found {source_members.count()} QMs from raw element")
                print(f"[DEBUG][DB Async][db_save_split_element] Original BIM volume ratio (clamped): {parent_volume_ratio:.6f} ({parent_volume_ratio * 100:.2f}%)")

            created_qm_count = 0
            created_ci_count = 0

            for source_member in source_members:
                # 2. QuantityMember ë³µì œ
                new_member = QuantityMember.objects.create(
                    project=project,
                    raw_element=raw_element,
                    classification_tag=source_member.classification_tag,
                    member_mark=source_member.member_mark,
                    name=source_member.name,
                    properties=source_member.properties.copy() if source_member.properties else {},
                    mapping_expression=source_member.mapping_expression.copy() if source_member.mapping_expression else {},
                    member_mark_expression=source_member.member_mark_expression,
                    cost_code_expressions=source_member.cost_code_expressions.copy() if source_member.cost_code_expressions else [],
                    is_active=True,
                    split_element=split_element,
                    source_quantity_member=source_member
                )

                # ManyToMany ê´€ê³„ ë³µì‚¬
                new_member.cost_codes.set(source_member.cost_codes.all())
                new_member.space_classifications.set(source_member.space_classifications.all())
                created_qm_count += 1

                # 3. ì›ë³¸ QuantityMemberë¥¼ ë¹„í™œì„±í™”
                source_member.is_active = False
                source_member.save(update_fields=['is_active'])

                # 4. CostItem ë³µì œ ë° ìˆ˜ëŸ‰ ì ìš©
                # â–¼â–¼â–¼ [ìˆ˜ì •] is_active í•„í„° ì œê±°: ì²« ë²ˆì§¸ splitì—ì„œ ë¹„í™œì„±í™”ë˜ì–´ë„ ë‘ ë²ˆì§¸ splitì—ì„œ ë³µì œ ê°€ëŠ¥ â–¼â–¼â–¼
                source_cost_items = CostItem.objects.filter(
                    quantity_member=source_member
                )

                for source_item in source_cost_items:
                    # â–¼â–¼â–¼ [ìˆ˜ì •] ë¶€ëª¨ ëŒ€ë¹„ ì²´ì  ë¹„ìœ¨ì„ ì ìš©í•œ ìˆ˜ëŸ‰ ê³„ì‚° â–¼â–¼â–¼
                    # parent_volume_ratio: ì§ì „ ë¶€ëª¨(parent_split ë˜ëŠ” raw_element) ëŒ€ë¹„ ë¹„ìœ¨
                    # ì´ë ‡ê²Œ í•˜ë©´ 2ì°¨, 3ì°¨ ë¶„í•  ì‹œì—ë„ ìˆ˜ëŸ‰ì´ ì •í™•í•˜ê²Œ ìœ ì§€ë¨
                    new_quantity = float(source_item.quantity) * parent_volume_ratio

                    new_item = CostItem.objects.create(
                        project=project,
                        quantity_member=new_member,
                        cost_code=source_item.cost_code,
                        quantity=new_quantity,
                        quantity_mapping_expression=source_item.quantity_mapping_expression.copy() if source_item.quantity_mapping_expression else {},
                        unit_price_type=source_item.unit_price_type,
                        description=source_item.description,
                        is_active=True,
                        split_element=split_element,
                        source_cost_item=source_item,
                        volume_ratio_applied=split_element.volume_ratio
                    )
                    created_ci_count += 1

                    # 5. ì›ë³¸ CostItemì„ ë¹„í™œì„±í™”
                    source_item.is_active = False
                    source_item.save(update_fields=['is_active'])

            print(f"[DEBUG][DB Async][db_save_split_element] Created {created_qm_count} QuantityMembers and {created_ci_count} CostItems")
            print(f"[DEBUG][DB Async][db_save_split_element] Applied parent volume ratio {parent_volume_ratio:.4f} ({parent_volume_ratio * 100:.2f}%) to all quantities")
            print(f"[DEBUG][DB Async][db_save_split_element] Note: volume_ratio (original BIM) = {float(split_element.volume_ratio):.4f}, parent_volume_ratio = {parent_volume_ratio:.4f}")
            # â–²â–²â–² ë³µì œ ë¡œì§ ë â–²â–²â–²

            return {
                'split_id': split_element.id,
                'created_qm_count': created_qm_count,
                'created_ci_count': created_ci_count
            }

        except Project.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] Project {payload.get('project_id')} not found")
            raise Exception(f"Project {payload.get('project_id')} not found")
        except RawElement.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] RawElement {payload.get('raw_element_id')} not found")
            raise Exception(f"RawElement {payload.get('raw_element_id')} not found")
        except SplitElement.DoesNotExist:
            print(f"[ERROR][DB Async][db_save_split_element] Parent split {payload.get('parent_split_id')} not found")
            raise Exception(f"Parent split {payload.get('parent_split_id')} not found")
        except Exception as e:
            print(f"[ERROR][DB Async][db_save_split_element] Exception during save: {e}")
            raise e
    # â–²â–²â–² [ì¶”ê°€] ì—¬ê¸°ê¹Œì§€ â–²â–²â–²